{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1978448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import pygsheets\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2f3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revcircle_damages_dict(ROW):    \n",
    "    DETAIL = ROW['Details']\n",
    "    REV_CIRCLE_DAMAGES_DICT = dict()\n",
    "    \n",
    "    count = 0\n",
    "    rev_circles_identified = []\n",
    "    rev_circles_identifed_at = []\n",
    "    for REV_CIRCLE in REVENUE_CIRCLES:\n",
    "        if REV_CIRCLE in DETAIL:\n",
    "            rev_circles_identified.append(REV_CIRCLE)\n",
    "            rev_circles_identifed_at.append(DETAIL.index(REV_CIRCLE))\n",
    "            count = count+1\n",
    "    REV_CIRCLES_IDENTIFIED_DF = pd.DataFrame([rev_circles_identified,rev_circles_identifed_at]).T\n",
    "    REV_CIRCLES_IDENTIFIED_DF.columns = ['RevenueCircle','StringIndex']\n",
    "    REV_CIRCLES_IDENTIFIED_DF = REV_CIRCLES_IDENTIFIED_DF.sort_values(by='StringIndex').reset_index(drop=True)\n",
    "    \n",
    "    for i,val in enumerate(REV_CIRCLES_IDENTIFIED_DF.StringIndex):\n",
    "        StringStartIndex = val\n",
    "        if i+1 == len(REV_CIRCLES_IDENTIFIED_DF.StringIndex):\n",
    "            StringEndIndex = None\n",
    "        else:\n",
    "            StringEndIndex = REV_CIRCLES_IDENTIFIED_DF.StringIndex[i+1]\n",
    "        \n",
    "        SUB_DETAIL = DETAIL[StringStartIndex:StringEndIndex]\n",
    "        \n",
    "        if other_damages == True:\n",
    "            NO_DAMAGES = len(re.findall('\\|', SUB_DETAIL))\n",
    "            print(NO_DAMAGES)\n",
    "            REV_CIRCLE_DAMAGES_DICT[REV_CIRCLES_IDENTIFIED_DF.RevenueCircle[i].split('-')[0]] = NO_DAMAGES-1\n",
    "            continue \n",
    "            \n",
    "        NO_DAMAGES_DateAlgo = len(re.findall('2023',SUB_DETAIL)) + len(re.findall(r'\\d+/\\d+/\\d{2}\\s+', SUB_DETAIL)) + len(re.findall(r'\\d+-\\d+-\\d{2}\\s+', SUB_DETAIL)) + len(re.findall(r'\\d+\\.\\d+\\.\\d{2}\\s+', SUB_DETAIL))\n",
    "        # Number of 2022 in the DETAIL +  Number of dd/mm/22 in the DETAIL +  Number of dd-mm-22 in the DETAIL + Number of dd.mm.22 in the DETAIL\n",
    "        NO_DAMAGES_LongAlgo = len(re.findall('Long -',SUB_DETAIL)) \n",
    "    \n",
    "        if float(ROW['Number of Damages (Long)'])==float(ROW['Number']):\n",
    "            REV_CIRCLE_DAMAGES_DICT[REV_CIRCLES_IDENTIFIED_DF.RevenueCircle[i].split('-')[0]] = NO_DAMAGES_LongAlgo\n",
    "        elif float(ROW['Number of Damages (Long)'])>float(ROW['Number of Damages (Date)']):\n",
    "            REV_CIRCLE_DAMAGES_DICT[REV_CIRCLES_IDENTIFIED_DF.RevenueCircle[i].split('-')[0]] = NO_DAMAGES_LongAlgo\n",
    "        else:\n",
    "            REV_CIRCLE_DAMAGES_DICT[REV_CIRCLES_IDENTIFIED_DF.RevenueCircle[i].split('-')[0]] = NO_DAMAGES_DateAlgo\n",
    "    \n",
    "    \n",
    "    return REV_CIRCLE_DAMAGES_DICT    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912f04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAM_REVENUE_CIRCLES = pd.read_csv('Data/Assam_Maps/ASSAM_REVENUE_CIRCLES_FRIMS_NAMES.csv')\n",
    "ASSAM_REVENUE_CIRCLES.revenue_ci = ASSAM_REVENUE_CIRCLES.revenue_ci.str.replace(r'\\(Pt\\)','', regex=True)\n",
    "ASSAM_REVENUE_CIRCLES.revenue_ci = ASSAM_REVENUE_CIRCLES.revenue_ci.str.replace(r'\\(Pt-I\\)','', regex=True)\n",
    "ASSAM_REVENUE_CIRCLES.revenue_ci = ASSAM_REVENUE_CIRCLES.revenue_ci.str.replace(r'\\(Pt-II\\)','', regex=True)\n",
    "\n",
    "ASSAM_REVENUE_CIRCLES.revenue_ci = ASSAM_REVENUE_CIRCLES.revenue_ci.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785d49a",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "* [Roads damaged per revenue circle](#roadsdamaged)\n",
    "* [Embankment damages per revenue circle](#embankmentdamages)\n",
    "* [Embankments affected per revenue circle](#embankmentaffected)\n",
    "* [Bridges damaged per revenue circle](#bridgesdamaged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133c003",
   "metadata": {},
   "source": [
    "## EMBANKMENT AFFECTED <a class=\"anchor\" id=\"embankmentaffected\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a116d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>District</th>\n",
       "      <th>Number</th>\n",
       "      <th>Details</th>\n",
       "      <th>state</th>\n",
       "      <th>ID</th>\n",
       "      <th>assam_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>DHEMAJI</td>\n",
       "      <td>1</td>\n",
       "      <td>Jonai - Tako to Borang charabari under PMGSY P...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>7</td>\n",
       "      <td>2011Dhem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-07-14</td>\n",
       "      <td>MAJULI</td>\n",
       "      <td>1</td>\n",
       "      <td>Ujani Majuli - UN-Embankment | Borpamua | Affe...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>18</td>\n",
       "      <td>2019Maju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>GOLAGHAT</td>\n",
       "      <td>1</td>\n",
       "      <td>Bokakhat - Brahmaputra Dyke from KRF boundary ...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>6</td>\n",
       "      <td>2011Gola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>MAJULI</td>\n",
       "      <td>2</td>\n",
       "      <td>Ujani Majuli - Un-Embankment | Jengrai Kumarba...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>18</td>\n",
       "      <td>2019Maju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>1</td>\n",
       "      <td>Gohpur - Bank erosion is observed on R/Bank em...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   District  Number  \\\n",
       "46  2023-07-12    DHEMAJI       1   \n",
       "47  2023-07-14     MAJULI       1   \n",
       "48  2023-07-15   GOLAGHAT       1   \n",
       "49  2023-07-15     MAJULI       2   \n",
       "50  2023-07-17  BISWANATH       1   \n",
       "\n",
       "                                              Details  state  ID assam_dist  \n",
       "46  Jonai - Tako to Borang charabari under PMGSY P...  ASSAM   7   2011Dhem  \n",
       "47  Ujani Majuli - UN-Embankment | Borpamua | Affe...  ASSAM  18   2019Maju  \n",
       "48  Bokakhat - Brahmaputra Dyke from KRF boundary ...  ASSAM   6   2011Gola  \n",
       "49  Ujani Majuli - Un-Embankment | Jengrai Kumarba...  ASSAM  18   2019Maju  \n",
       "50  Gohpur - Bank erosion is observed on R/Bank em...  ASSAM  24   2019Bisw  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embankments_affected_df = pd.read_csv('Data_2023/Cleaned Data/DISTRICTS_FRIMS_EMBANKMENTS_AFFECTED_MASTER_2023.csv')\n",
    "embankments_affected_df['Details'] = embankments_affected_df['Details'].str.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "embankments_affected_df['Details'] = embankments_affected_df.Details.str.replace('Baghbar','Baghbor',regex=True)\n",
    "embankments_affected_df['Details'] = embankments_affected_df.Details.str.replace('Dotma','Dotoma',regex=True)\n",
    "embankments_affected_df['Details'] = embankments_affected_df.Details.str.replace('Palashbari','Palasbari',regex=True)\n",
    "embankments_affected_df['Details'] = embankments_affected_df.Details.str.replace('North Ghy','North\\nGuwahati',regex=True)\n",
    "embankments_affected_df['Details'] = embankments_affected_df.Details.str.replace('Khairabari','Khoirabari',regex=True)\n",
    "embankments_affected_df['Details'] = embankments_affected_df.Details.str.replace('Dangtol','Bongaigaon',regex=True)\n",
    "embankments_affected_df['Details'] = embankments_affected_df.Details.str.replace('Naduar','Na-Duar',regex=True)\n",
    "\n",
    "embankments_affected_df['District'] = embankments_affected_df.District.str.replace('Dima-Hasao','Dima Hasao',regex=True)\n",
    "embankments_affected_df['District'] = embankments_affected_df.District.str.replace('Sivasagar','Sivsagar',regex=True)\n",
    "\n",
    "\n",
    "embankments_affected_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042a30d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHEMAJI\n",
      "['Dhakuakhana -', 'Dhemaji -', 'Gogamukh -', 'Jonai -', 'Sissiborgaon -', 'Subansiri -']\n",
      "----\n",
      "BISWANATH\n",
      "['Biswanath -', 'Gohpur -', 'Halem -']\n",
      "----\n",
      "DARRANG\n",
      "['Dalgaon -', 'Khoirabari -', 'Mangaldoi -', 'Patharighat -', 'Sipajhar -']\n",
      "----\n",
      "TAMULPUR\n",
      "['Bajali -', 'Goreswar -', 'Pathorighat -', 'Rangia -', 'Tamulpur -']\n",
      "----\n",
      "GOLAGHAT\n",
      "['Bokakhat -', 'Dergaon -', 'Golaghat -', 'Khumtai -', 'Morangi -', 'Sarupathar -']\n",
      "----\n",
      "KARIMGANJ\n",
      "['Badarpur -', 'Karimganj -', 'Nilambazar -', 'Patherkandi -', 'RK Nagar -']\n",
      "----\n",
      "GOALPARA\n",
      "['Balijana -', 'Dudhnoi -', 'Lakhipur -', 'Matia -', 'Rangjuli -']\n",
      "----\n",
      "LAKHIMPUR\n",
      "['Bihpuria -', 'Dhakuakhana -', 'Kadam -', 'Narayanpur -', 'North Lakhimpur -', 'Nowboicha -', 'Subansiri -']\n",
      "----\n",
      "NALBARI\n",
      "['Baganpara -', 'Banekuchi -', 'Barbhag -', 'Barkhetri -', 'Ghograpar -', 'Nalbari -', 'Pachim\\nNalbari -', 'Tihu -']\n",
      "----\n",
      "NAGAON\n",
      "['Dhing -', 'Kaliabor -', 'Kampur -', 'Nagaon -', 'Raha -', 'Rupahi -', 'Samaguri -']\n",
      "----\n",
      "BAJALI\n",
      "['Bajali -', 'Jalah -', 'Sarupeta -']\n",
      "----\n",
      "KOKRAJHAR\n",
      "['Bagribari -', 'Bhawraguri -', 'Chapar -', 'Dhubri -', 'Dotoma -', 'Golokganj -', 'Gossaigaon -', 'Kokrajhar -']\n",
      "----\n",
      "KAMRUP\n",
      "['Azara -', 'Boko -', 'Chamaria -', 'Chhaygaon -', 'Goroimari -', 'Hajo -', 'Jalah -', 'Kamalpur -', 'Kayan -', 'Nagarbera -', 'North\\nGuwahati -', 'Palasbari -', 'Rangia -']\n",
      "----\n",
      "DIBRUGARH\n",
      "['Chabua -', 'Dibrugarh East -', 'Dibrugarh West -', 'Moran -', 'Naharkatia -', 'Tengakhat -', 'Tingkhong -']\n",
      "----\n",
      "MAJULI\n",
      "['Majuli -', 'Ujani Majuli -']\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11725/797364889.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "global REVENUE_CIRCLES\n",
    "global other_damages\n",
    "other_damages = False\n",
    "\n",
    "FILTERED_DAMAGES_dfs = []\n",
    "\n",
    "for DISTRICT in embankments_affected_df.District.unique():\n",
    "    print(DISTRICT)\n",
    "    FILTERED_DAMAGES_df = embankments_affected_df[embankments_affected_df.District == DISTRICT]\n",
    "    FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.sort_values(by=['Detail_Length'])\n",
    "    \n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.drop_duplicates(['District','Number','Date'],keep='last')\n",
    "    \n",
    "    FILTERED_DAMAGES_df['Number of Damages (Date)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('2023', x))+len(re.findall(r'\\d+/\\d+/\\d{2}\\s+',x))+len(re.findall(r'\\d+-\\d+-\\d{2}\\s+',x))+len(re.findall(r'\\d+\\.\\d+\\.\\d{2}\\s+', x)))\n",
    "    FILTERED_DAMAGES_df['Number of Damages (Long)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('Long -', x)))\n",
    "        \n",
    "    \n",
    "    REVENUE_CIRCLES = [REV_CIRCLE.strip()+' -' for REV_CIRCLE in list(ASSAM_REVENUE_CIRCLES[ASSAM_REVENUE_CIRCLES.district_35==DISTRICT.upper()].revenue_ci)]\n",
    "    print(REVENUE_CIRCLES)\n",
    "    print('----')\n",
    "    FILTERED_DAMAGES_df['NumberofDamages_RevenueCircle_level'] = FILTERED_DAMAGES_df.apply(get_revcircle_damages_dict, axis=1)\n",
    "    FILTERED_DAMAGES_dfs.append(FILTERED_DAMAGES_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916776c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_DAMAGES = pd.concat(FILTERED_DAMAGES_dfs).reset_index(drop=True)\n",
    "MASTER_DAMAGES.District = MASTER_DAMAGES.District.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e70349",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_affected_revcircle_df = pd.DataFrame(columns=['District','RevenueCircle','Number of damages','Date'])\n",
    "i = 0\n",
    "for idx, row in MASTER_DAMAGES.iterrows():\n",
    "    damages_dict = row['NumberofDamages_RevenueCircle_level']\n",
    "    for key in damages_dict.keys():\n",
    "        rev_circle = key\n",
    "        no_damages = damages_dict[key]\n",
    "        \n",
    "        embankment_affected_revcircle_df.loc[i,'RevenueCircle'] = rev_circle\n",
    "        embankment_affected_revcircle_df.loc[i,'District'] = row['District']\n",
    "        embankment_affected_revcircle_df.loc[i,'Number of damages'] = no_damages\n",
    "        embankment_affected_revcircle_df.loc[i,'Date'] = row['Date']\n",
    "        i=i+1\n",
    "embankment_affected_revcircle_df.Date = pd.to_datetime(embankment_affected_revcircle_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "877e76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_affected_revcircle_df.RevenueCircle =embankment_affected_revcircle_df.RevenueCircle.str.strip()\n",
    "embankment_affected_revcircle_df.loc[embankment_affected_revcircle_df.RevenueCircle == 'Na', 'RevenueCircle'] = 'Na-Duar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff4f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_affected_revcircle_df = pd.merge(embankment_affected_revcircle_df,\n",
    "                                ASSAM_REVENUE_CIRCLES[['district_35', 'revenue_ci','object_id']],\n",
    "                                left_on=['District', 'RevenueCircle'],\n",
    "                                right_on=['district_35', 'revenue_ci'],\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08c0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_affected_revcircle_df = embankment_affected_revcircle_df[['Date','object_id','revenue_ci','District','Number of damages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcba3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_affected_revcircle_df.to_csv('Data_2023/Cleaned Data/RC_FRIMS_EMBANKMENTS_AFFECTED_MASTER_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad480d1",
   "metadata": {},
   "source": [
    "## EMBANKMENT BREACHES <a class=\"anchor\" id=\"embankmentbreaches\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b28bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>District</th>\n",
       "      <th>Number</th>\n",
       "      <th>Details</th>\n",
       "      <th>state</th>\n",
       "      <th>ID</th>\n",
       "      <th>assam_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>1</td>\n",
       "      <td>Halem - At upstream ofTinikuniaon R/Bank TeaGa...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>JORHAT</td>\n",
       "      <td>1</td>\n",
       "      <td>Teok - Teok river left ring bund | Dakhin Duli...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>22</td>\n",
       "      <td>2011Jorh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-07-09</td>\n",
       "      <td>JORHAT</td>\n",
       "      <td>1</td>\n",
       "      <td>Teok - Right ring bund of river Teok | Dakhin ...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>22</td>\n",
       "      <td>2011Jorh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>1</td>\n",
       "      <td>Halem - Tupung river embankment | Jogibari | S...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>UDALGURI</td>\n",
       "      <td>1</td>\n",
       "      <td>Udalguri - Dhansiri Irrigation Project | Vilag...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>21</td>\n",
       "      <td>2011Udal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   District  Number  \\\n",
       "25  2023-06-28  BISWANATH       1   \n",
       "26  2023-06-29     JORHAT       1   \n",
       "27  2023-07-09     JORHAT       1   \n",
       "28  2023-07-10  BISWANATH       1   \n",
       "29  2023-07-11   UDALGURI       1   \n",
       "\n",
       "                                              Details  state  ID assam_dist  \n",
       "25  Halem - At upstream ofTinikuniaon R/Bank TeaGa...  ASSAM  24   2019Bisw  \n",
       "26  Teok - Teok river left ring bund | Dakhin Duli...  ASSAM  22   2011Jorh  \n",
       "27  Teok - Right ring bund of river Teok | Dakhin ...  ASSAM  22   2011Jorh  \n",
       "28  Halem - Tupung river embankment | Jogibari | S...  ASSAM  24   2019Bisw  \n",
       "29  Udalguri - Dhansiri Irrigation Project | Vilag...  ASSAM  21   2011Udal  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embankments_breached_df = pd.read_csv('Data_2023/Cleaned Data/DISTRICTS_FRIMS_EMBANKMENTS_BREACHED_MASTER_2023.csv')\n",
    "embankments_breached_df['Details'] = embankments_breached_df['Details'].str.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "embankments_breached_df['Details'] = embankments_breached_df.Details.str.replace('Baghbar','Baghbor',regex=True)\n",
    "embankments_breached_df['Details'] = embankments_breached_df.Details.str.replace('Dotma','Dotoma',regex=True)\n",
    "embankments_breached_df['Details'] = embankments_breached_df.Details.str.replace('Palashbari','Palasbari',regex=True)\n",
    "embankments_breached_df['Details'] = embankments_breached_df.Details.str.replace('North Ghy','North\\nGuwahati',regex=True)\n",
    "embankments_breached_df['Details'] = embankments_breached_df.Details.str.replace('Khairabari','Khoirabari',regex=True)\n",
    "embankments_breached_df['Details'] = embankments_breached_df.Details.str.replace('Dangtol','Bongaigaon',regex=True)\n",
    "embankments_breached_df['Details'] = embankments_breached_df.Details.str.replace('Naduar','Na-Duar',regex=True)\n",
    "\n",
    "\n",
    "embankments_breached_df['District'] = embankments_breached_df.District.str.replace('Dima-Hasao','Dima Hasao',regex=True)\n",
    "embankments_breached_df['District'] = embankments_breached_df.District.str.replace('Sivasagar','Sivsagar',regex=True)\n",
    "\n",
    "\n",
    "embankments_breached_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461d4ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BISWANATH\n",
      "['Biswanath -', 'Gohpur -', 'Halem -']\n",
      "----\n",
      "LAKHIMPUR\n",
      "['Bihpuria -', 'Dhakuakhana -', 'Kadam -', 'Narayanpur -', 'North Lakhimpur -', 'Nowboicha -', 'Subansiri -']\n",
      "----\n",
      "DARRANG\n",
      "['Dalgaon -', 'Khoirabari -', 'Mangaldoi -', 'Patharighat -', 'Sipajhar -']\n",
      "----\n",
      "GOALPARA\n",
      "['Balijana -', 'Dudhnoi -', 'Lakhipur -', 'Matia -', 'Rangjuli -']\n",
      "----\n",
      "UDALGURI\n",
      "['Dalgaon -', 'Dhekiajuli -', 'Harisinga -', 'Kalaigaon -', 'Khoirabari -', 'Mangaldoi -', 'Mazbat -', 'Pathorighat -', 'Udalguri -']\n",
      "----\n",
      "SONITPUR\n",
      "['Chariduar -', 'Dhekiajuli -', 'Na-Duar -', 'Tezpur -']\n",
      "----\n",
      "NAGAON\n",
      "['Dhing -', 'Kaliabor -', 'Kampur -', 'Nagaon -', 'Raha -', 'Rupahi -', 'Samaguri -']\n",
      "----\n",
      "BAKSA\n",
      "['Baganpara -', 'Barama -', 'Barnagar -', 'Baska -', 'Ghograpar -', 'Jalah -', 'Sarupeta -']\n",
      "----\n",
      "NALBARI\n",
      "['Baganpara -', 'Banekuchi -', 'Barbhag -', 'Barkhetri -', 'Ghograpar -', 'Nalbari -', 'Pachim\\nNalbari -', 'Tihu -']\n",
      "----\n",
      "BAJALI\n",
      "['Bajali -', 'Jalah -', 'Sarupeta -']\n",
      "----\n",
      "JORHAT\n",
      "['Jorhat East -', 'Jorhat West -', 'Mariani -', 'Teok -', 'Titabor -']\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11725/1701030496.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "global REVENUE_CIRCLES\n",
    "global other_damages\n",
    "other_damages = False\n",
    "\n",
    "FILTERED_DAMAGES_dfs = []\n",
    "\n",
    "for DISTRICT in embankments_breached_df.District.unique():\n",
    "    print(DISTRICT)\n",
    "    FILTERED_DAMAGES_df = embankments_breached_df[embankments_breached_df.District == DISTRICT]\n",
    "    FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.sort_values(by=['Detail_Length'])\n",
    "    \n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.drop_duplicates(['District','Number','Date'],keep='last')\n",
    "    \n",
    "    FILTERED_DAMAGES_df['Number of Damages (Date)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('2022', x))+len(re.findall(r'\\d+/\\d+/\\d{2}\\s+',x))+len(re.findall(r'\\d+-\\d+-\\d{2}\\s+',x))+len(re.findall(r'\\d+\\.\\d+\\.\\d{2}\\s+', x)))\n",
    "    FILTERED_DAMAGES_df['Number of Damages (Long)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('Long -', x)))\n",
    "        \n",
    "    \n",
    "    REVENUE_CIRCLES = [REV_CIRCLE.strip()+' -' for REV_CIRCLE in list(ASSAM_REVENUE_CIRCLES[ASSAM_REVENUE_CIRCLES.district_35==DISTRICT.upper()].revenue_ci)]\n",
    "    print(REVENUE_CIRCLES)\n",
    "    print('----')\n",
    "    FILTERED_DAMAGES_df['NumberofDamages_RevenueCircle_level'] = FILTERED_DAMAGES_df.apply(get_revcircle_damages_dict, axis=1)\n",
    "    FILTERED_DAMAGES_dfs.append(FILTERED_DAMAGES_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a35e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_DAMAGES = pd.concat(FILTERED_DAMAGES_dfs).reset_index(drop=True)\n",
    "MASTER_DAMAGES.District = MASTER_DAMAGES.District.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16df1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_breaches_revcircle_df = pd.DataFrame(columns=['District','RevenueCircle','Number of damages','Date'])\n",
    "i = 0\n",
    "for idx, row in MASTER_DAMAGES.iterrows():\n",
    "    damages_dict = row['NumberofDamages_RevenueCircle_level']\n",
    "    for key in damages_dict.keys():\n",
    "        rev_circle = key\n",
    "        no_damages = damages_dict[key]\n",
    "        \n",
    "        embankment_breaches_revcircle_df.loc[i,'RevenueCircle'] = rev_circle\n",
    "        embankment_breaches_revcircle_df.loc[i,'District'] = row['District']\n",
    "        embankment_breaches_revcircle_df.loc[i,'Number of damages'] = no_damages\n",
    "        embankment_breaches_revcircle_df.loc[i,'Date'] = row['Date']\n",
    "        i=i+1\n",
    "embankment_breaches_revcircle_df.Date = pd.to_datetime(embankment_breaches_revcircle_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed9cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_breaches_revcircle_df.RevenueCircle =embankment_breaches_revcircle_df.RevenueCircle.str.strip()\n",
    "embankment_breaches_revcircle_df.loc[embankment_breaches_revcircle_df.RevenueCircle == 'Na', 'RevenueCircle'] = 'Na-Duar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d75a9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_breaches_revcircle_df = pd.merge(embankment_breaches_revcircle_df,\n",
    "                                ASSAM_REVENUE_CIRCLES[['district_35', 'revenue_ci','object_id']],\n",
    "                                left_on=['District', 'RevenueCircle'],\n",
    "                                right_on=['district_35', 'revenue_ci'],\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1ed7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_breaches_revcircle_df = embankment_breaches_revcircle_df[['Date','object_id','revenue_ci','District','Number of damages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c4fd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embankment_breaches_revcircle_df.to_csv('Data_2023/Cleaned Data/RC_FRIMS_EMBANKMENTS_BREACHED_MASTER_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313391e",
   "metadata": {},
   "source": [
    "## BRIDGES DAMAGED <a class=\"anchor\" id=\"bridgesdamaged\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf53c2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>District</th>\n",
       "      <th>Number</th>\n",
       "      <th>Details</th>\n",
       "      <th>state</th>\n",
       "      <th>ID</th>\n",
       "      <th>assam_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>1</td>\n",
       "      <td>Halem - R.C.C Br.No.1/2 - Approch | Borjohabar...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>GOLAGHAT</td>\n",
       "      <td>2</td>\n",
       "      <td>Bokakhat - Kamalamiri Ali, L=6.00km ( RCC Br. ...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>6</td>\n",
       "      <td>2011Gola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>BARPETA</td>\n",
       "      <td>1</td>\n",
       "      <td>Sarthebari - Baithabhanga Pithadi Road SPT Br ...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>32</td>\n",
       "      <td>2011Barp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>BONGAIGAON</td>\n",
       "      <td>1</td>\n",
       "      <td>Manikpur - Kawadi to Sonaikhola Road | Sonaikh...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>10</td>\n",
       "      <td>2011Bong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-07-18</td>\n",
       "      <td>DHEMAJI</td>\n",
       "      <td>1</td>\n",
       "      <td>Dhemaji - Shilpata road from Tanganapara to Ma...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>7</td>\n",
       "      <td>2011Dhem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date    District  Number  \\\n",
       "27  2023-07-10   BISWANATH       1   \n",
       "28  2023-07-11    GOLAGHAT       2   \n",
       "29  2023-07-13     BARPETA       1   \n",
       "30  2023-07-17  BONGAIGAON       1   \n",
       "31  2023-07-18     DHEMAJI       1   \n",
       "\n",
       "                                              Details  state  ID assam_dist  \n",
       "27  Halem - R.C.C Br.No.1/2 - Approch | Borjohabar...  ASSAM  24   2019Bisw  \n",
       "28  Bokakhat - Kamalamiri Ali, L=6.00km ( RCC Br. ...  ASSAM   6   2011Gola  \n",
       "29  Sarthebari - Baithabhanga Pithadi Road SPT Br ...  ASSAM  32   2011Barp  \n",
       "30  Manikpur - Kawadi to Sonaikhola Road | Sonaikh...  ASSAM  10   2011Bong  \n",
       "31  Dhemaji - Shilpata road from Tanganapara to Ma...  ASSAM   7   2011Dhem  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bridges_df = pd.read_csv('Data_2023/Cleaned Data/DISTRICTS_FRIMS_BRIDGES_DAMAGED_MASTER_2023.csv')\n",
    "bridges_df['Details'] = bridges_df['Details'].str.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "bridges_df['Details'] = bridges_df.Details.str.replace('Baghbar','Baghbor',regex=True)\n",
    "bridges_df['Details'] = bridges_df.Details.str.replace('Dotma','Dotoma',regex=True)\n",
    "bridges_df['Details'] = bridges_df.Details.str.replace('Palashbari','Palasbari',regex=True)\n",
    "bridges_df['Details'] = bridges_df.Details.str.replace('North Ghy','North\\nGuwahati',regex=True)\n",
    "bridges_df['Details'] = bridges_df.Details.str.replace('Khairabari','Khoirabari',regex=True)\n",
    "bridges_df['Details'] = bridges_df.Details.str.replace('Dangtol','Bongaigaon',regex=True)\n",
    "bridges_df['Details'] = bridges_df.Details.str.replace('Naduar','Na-Duar',regex=True)\n",
    "\n",
    "\n",
    "bridges_df['District'] = bridges_df.District.str.replace('Dima-Hasao','Dima Hasao',regex=True)\n",
    "bridges_df['District'] = bridges_df.District.str.replace('Sivasagar','Sivsagar',regex=True)\n",
    "\n",
    "\n",
    "bridges_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83e59710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHEMAJI\n",
      "['Dhakuakhana -', 'Dhemaji -', 'Gogamukh -', 'Jonai -', 'Sissiborgaon -', 'Subansiri -']\n",
      "----\n",
      "SONITPUR\n",
      "['Chariduar -', 'Dhekiajuli -', 'Na-Duar -', 'Tezpur -']\n",
      "----\n",
      "DARRANG\n",
      "['Dalgaon -', 'Khoirabari -', 'Mangaldoi -', 'Patharighat -', 'Sipajhar -']\n",
      "----\n",
      "KOKRAJHAR\n",
      "['Bagribari -', 'Bhawraguri -', 'Chapar -', 'Dhubri -', 'Dotoma -', 'Golokganj -', 'Gossaigaon -', 'Kokrajhar -']\n",
      "----\n",
      "BARPETA\n",
      "['Baghbor -', 'Barnagar -', 'Barpeta -', 'Chenga -', 'Kalgachia -', 'Sarthebari -']\n",
      "----\n",
      "BONGAIGAON\n",
      "['Boitamari -', 'Bongaigaon -', 'Manikpur -', 'Sidli -', 'Srijangram -']\n",
      "----\n",
      "BAKSA\n",
      "['Baganpara -', 'Barama -', 'Barnagar -', 'Baska -', 'Ghograpar -', 'Jalah -', 'Sarupeta -']\n",
      "----\n",
      "NALBARI\n",
      "['Baganpara -', 'Banekuchi -', 'Barbhag -', 'Barkhetri -', 'Ghograpar -', 'Nalbari -', 'Pachim\\nNalbari -', 'Tihu -']\n",
      "----\n",
      "BISWANATH\n",
      "['Biswanath -', 'Gohpur -', 'Halem -']\n",
      "----\n",
      "DHUBRI\n",
      "['Agamoni -', 'Bagribari -', 'Bilasipara -', 'Chapar -', 'Dhubri -', 'Golakganj -', 'Gossaigaon -']\n",
      "----\n",
      "BAJALI\n",
      "['Bajali -', 'Jalah -', 'Sarupeta -']\n",
      "----\n",
      "GOLAGHAT\n",
      "['Bokakhat -', 'Dergaon -', 'Golaghat -', 'Khumtai -', 'Morangi -', 'Sarupathar -']\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11725/1577161483.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "global REVENUE_CIRCLES\n",
    "global other_damages\n",
    "other_damages = False\n",
    "\n",
    "FILTERED_DAMAGES_dfs = []\n",
    "\n",
    "for DISTRICT in bridges_df.District.unique():\n",
    "    print(DISTRICT)\n",
    "    FILTERED_DAMAGES_df = bridges_df[bridges_df.District == DISTRICT]\n",
    "    FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.sort_values(by=['Detail_Length'])\n",
    "    \n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.drop_duplicates(['District','Number','Date'],keep='last')\n",
    "    \n",
    "    FILTERED_DAMAGES_df['Number of Damages (Date)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('2022', x))+len(re.findall(r'\\d+/\\d+/\\d{2}\\s+',x))+len(re.findall(r'\\d+-\\d+-\\d{2}\\s+',x))+len(re.findall(r'\\d+\\.\\d+\\.\\d{2}\\s+', x)))\n",
    "    FILTERED_DAMAGES_df['Number of Damages (Long)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('Long -', x)))\n",
    "        \n",
    "    \n",
    "    REVENUE_CIRCLES = [REV_CIRCLE.strip()+' -' for REV_CIRCLE in list(ASSAM_REVENUE_CIRCLES[ASSAM_REVENUE_CIRCLES.district_35==DISTRICT.upper()].revenue_ci)]\n",
    "    print(REVENUE_CIRCLES)\n",
    "    print('----')\n",
    "    FILTERED_DAMAGES_df['NumberofDamages_RevenueCircle_level'] = FILTERED_DAMAGES_df.apply(get_revcircle_damages_dict, axis=1)\n",
    "    FILTERED_DAMAGES_dfs.append(FILTERED_DAMAGES_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "393ba6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_DAMAGES = pd.concat(FILTERED_DAMAGES_dfs).reset_index(drop=True)\n",
    "MASTER_DAMAGES.District = MASTER_DAMAGES.District.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2512901",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridges_revcircle_df = pd.DataFrame(columns=['District','RevenueCircle','Number of damages','Date'])\n",
    "i = 0\n",
    "for idx, row in MASTER_DAMAGES.iterrows():\n",
    "    damages_dict = row['NumberofDamages_RevenueCircle_level']\n",
    "    for key in damages_dict.keys():\n",
    "        rev_circle = key\n",
    "        no_damages = damages_dict[key]\n",
    "        \n",
    "        bridges_revcircle_df.loc[i,'RevenueCircle'] = rev_circle\n",
    "        bridges_revcircle_df.loc[i,'District'] = row['District']\n",
    "        bridges_revcircle_df.loc[i,'Number of damages'] = no_damages\n",
    "        bridges_revcircle_df.loc[i,'Date'] = row['Date']\n",
    "        i=i+1\n",
    "bridges_revcircle_df.Date = pd.to_datetime(bridges_revcircle_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c75f14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridges_revcircle_df.RevenueCircle =bridges_revcircle_df.RevenueCircle.str.strip()\n",
    "bridges_revcircle_df.loc[bridges_revcircle_df.RevenueCircle == 'Na', 'RevenueCircle'] = 'Na-Duar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d008364",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridges_revcircle_df = pd.merge(bridges_revcircle_df,\n",
    "                                ASSAM_REVENUE_CIRCLES[['district_35', 'revenue_ci','object_id']],\n",
    "                                left_on=['District', 'RevenueCircle'],\n",
    "                                right_on=['district_35', 'revenue_ci'],\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d22d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridges_revcircle_df = bridges_revcircle_df[['Date','object_id','revenue_ci','District','Number of damages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef1349b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridges_revcircle_df.to_csv('Data_2023/Cleaned Data/RC_FRIMS_BRIDGES_DAMAGED_MASTER_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84144e55",
   "metadata": {},
   "source": [
    "## ROADS DAMAGED <a class=\"anchor\" id=\"roadsdamaged\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a94d2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>District</th>\n",
       "      <th>Number</th>\n",
       "      <th>Details</th>\n",
       "      <th>state</th>\n",
       "      <th>ID</th>\n",
       "      <th>assam_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>1</td>\n",
       "      <td>Gohpur - Singarajan to Sutardoloni Kutcha Road...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>DARRANG</td>\n",
       "      <td>1</td>\n",
       "      <td>Mangaldoi - Approach road Noanadi Kachia Bund ...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>26</td>\n",
       "      <td>2011Darr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>6</td>\n",
       "      <td>Gohpur - Road from Borigaon to Deonabori. (A c...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>LAKHIMPUR</td>\n",
       "      <td>1</td>\n",
       "      <td>Narayanpur - Balikuchi Bishnupur Road at Ch 35...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>15</td>\n",
       "      <td>2011Lakh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>LAKHIMPUR</td>\n",
       "      <td>2</td>\n",
       "      <td>Nowboicha - Dolohat to Laluk Kachajuli PWD Roa...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>15</td>\n",
       "      <td>2011Lakh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   District  Number  \\\n",
       "0  2023-06-11  BISWANATH       1   \n",
       "1  2023-06-12    DARRANG       1   \n",
       "2  2023-06-12  BISWANATH       6   \n",
       "3  2023-06-13  LAKHIMPUR       1   \n",
       "4  2023-06-14  LAKHIMPUR       2   \n",
       "\n",
       "                                             Details  state  ID assam_dist  \n",
       "0  Gohpur - Singarajan to Sutardoloni Kutcha Road...  ASSAM  24   2019Bisw  \n",
       "1  Mangaldoi - Approach road Noanadi Kachia Bund ...  ASSAM  26   2011Darr  \n",
       "2  Gohpur - Road from Borigaon to Deonabori. (A c...  ASSAM  24   2019Bisw  \n",
       "3  Narayanpur - Balikuchi Bishnupur Road at Ch 35...  ASSAM  15   2011Lakh  \n",
       "4  Nowboicha - Dolohat to Laluk Kachajuli PWD Roa...  ASSAM  15   2011Lakh  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roads_damaged_df = pd.read_csv('Data_2023/Cleaned Data/DISTRICTS_FRIMS_ROADS_DAMAGED_MASTER_2023.csv')\n",
    "roads_damaged_df['Details'] = roads_damaged_df['Details'].str.replace('\\n', ' ')\n",
    "\n",
    "roads_damaged_df['Details'] = roads_damaged_df.Details.str.replace('Baghbar','Baghbor',regex=True)\n",
    "roads_damaged_df['Details'] = roads_damaged_df.Details.str.replace('Dotma','Dotoma',regex=True)\n",
    "roads_damaged_df['Details'] = roads_damaged_df.Details.str.replace('Palashbari','Palasbari',regex=True)\n",
    "roads_damaged_df['Details'] = roads_damaged_df.Details.str.replace('North Ghy','North\\nGuwahati',regex=True)\n",
    "roads_damaged_df['Details'] = roads_damaged_df.Details.str.replace('Khairabari','Khoirabari',regex=True)\n",
    "roads_damaged_df['Details'] = roads_damaged_df.Details.str.replace('Dangtol','Bongaigaon',regex=True)\n",
    "roads_damaged_df['Details'] = roads_damaged_df.Details.str.replace('Naduar','Na-Duar',regex=True)\n",
    "\n",
    "\n",
    "roads_damaged_df['District'] = roads_damaged_df.District.str.replace('Dima-Hasao','Dima Hasao',regex=True)\n",
    "roads_damaged_df['District'] = roads_damaged_df.District.str.replace('Sivasagar','Sivsagar',regex=True)\n",
    "\n",
    "\n",
    "roads_damaged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af78287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_damaged_df = roads_damaged_df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a78b3bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BISWANATH\n",
      "['Biswanath -', 'Gohpur -', 'Halem -']\n",
      "----\n",
      "DARRANG\n",
      "['Dalgaon -', 'Khoirabari -', 'Mangaldoi -', 'Patharighat -', 'Sipajhar -']\n",
      "----\n",
      "LAKHIMPUR\n",
      "['Bihpuria -', 'Dhakuakhana -', 'Kadam -', 'Narayanpur -', 'North Lakhimpur -', 'Nowboicha -', 'Subansiri -']\n",
      "----\n",
      "DHEMAJI\n",
      "['Dhakuakhana -', 'Dhemaji -', 'Gogamukh -', 'Jonai -', 'Sissiborgaon -', 'Subansiri -']\n",
      "----\n",
      "DIMA HASAO\n",
      "['Haflong -', 'Mahur -', 'Maibong -', 'Umrangso -']\n",
      "----\n",
      "GOALPARA\n",
      "['Balijana -', 'Dudhnoi -', 'Lakhipur -', 'Matia -', 'Rangjuli -']\n",
      "----\n",
      "NALBARI\n",
      "['Baganpara -', 'Banekuchi -', 'Barbhag -', 'Barkhetri -', 'Ghograpar -', 'Nalbari -', 'Pachim\\nNalbari -', 'Tihu -']\n",
      "----\n",
      "UDALGURI\n",
      "['Dalgaon -', 'Dhekiajuli -', 'Harisinga -', 'Kalaigaon -', 'Khoirabari -', 'Mangaldoi -', 'Mazbat -', 'Pathorighat -', 'Udalguri -']\n",
      "----\n",
      "TAMULPUR\n",
      "['Bajali -', 'Goreswar -', 'Pathorighat -', 'Rangia -', 'Tamulpur -']\n",
      "----\n",
      "KAMRUP\n",
      "['Azara -', 'Boko -', 'Chamaria -', 'Chhaygaon -', 'Goroimari -', 'Hajo -', 'Jalah -', 'Kamalpur -', 'Kayan -', 'Nagarbera -', 'North\\nGuwahati -', 'Palasbari -', 'Rangia -']\n",
      "----\n",
      "NAGAON\n",
      "['Dhing -', 'Kaliabor -', 'Kampur -', 'Nagaon -', 'Raha -', 'Rupahi -', 'Samaguri -']\n",
      "----\n",
      "CACHAR\n",
      "['Katigorah -', 'Lakhipur -', 'Silchar -', 'Sonai -', 'Udharbond -']\n",
      "----\n",
      "GOLAGHAT\n",
      "['Bokakhat -', 'Dergaon -', 'Golaghat -', 'Khumtai -', 'Morangi -', 'Sarupathar -']\n",
      "----\n",
      "CHIRANG\n",
      "['Barnagar -', 'Bengtal -', 'Bijni -', 'Kokrajhar -', 'Sidli -']\n",
      "----\n",
      "BAKSA\n",
      "['Baganpara -', 'Barama -', 'Barnagar -', 'Baska -', 'Ghograpar -', 'Jalah -', 'Sarupeta -']\n",
      "----\n",
      "KOKRAJHAR\n",
      "['Bagribari -', 'Bhawraguri -', 'Chapar -', 'Dhubri -', 'Dotoma -', 'Golokganj -', 'Gossaigaon -', 'Kokrajhar -']\n",
      "----\n",
      "BONGAIGAON\n",
      "['Boitamari -', 'Bongaigaon -', 'Manikpur -', 'Sidli -', 'Srijangram -']\n",
      "----\n",
      "KARIMGANJ\n",
      "['Badarpur -', 'Karimganj -', 'Nilambazar -', 'Patherkandi -', 'RK Nagar -']\n",
      "----\n",
      "DHUBRI\n",
      "['Agamoni -', 'Bagribari -', 'Bilasipara -', 'Chapar -', 'Dhubri -', 'Golakganj -', 'Gossaigaon -']\n",
      "----\n",
      "BAJALI\n",
      "['Bajali -', 'Jalah -', 'Sarupeta -']\n",
      "----\n",
      "BARPETA\n",
      "['Baghbor -', 'Barnagar -', 'Barpeta -', 'Chenga -', 'Kalgachia -', 'Sarthebari -']\n",
      "----\n",
      "MAJULI\n",
      "['Majuli -', 'Ujani Majuli -']\n",
      "----\n",
      "JORHAT\n",
      "['Jorhat East -', 'Jorhat West -', 'Mariani -', 'Teok -', 'Titabor -']\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11725/993252146.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONITPUR\n",
      "['Chariduar -', 'Dhekiajuli -', 'Na-Duar -', 'Tezpur -']\n",
      "----\n",
      "CHARAIDEO\n",
      "['Mahmora -', 'Sapekhati -', 'Sonari -']\n",
      "----\n",
      "MORIGAON\n",
      "['Bhuragaon -', 'Laharighat -', 'Mayong -', 'Mikirbheta -', 'Morigaon -']\n",
      "----\n",
      "DIBRUGARH\n",
      "['Chabua -', 'Dibrugarh East -', 'Dibrugarh West -', 'Moran -', 'Naharkatia -', 'Tengakhat -', 'Tingkhong -']\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "global REVENUE_CIRCLES\n",
    "global other_damages\n",
    "other_damages = False\n",
    "\n",
    "FILTERED_DAMAGES_dfs = []\n",
    "\n",
    "for DISTRICT in roads_damaged_df.District.unique():\n",
    "    print(DISTRICT)\n",
    "    FILTERED_DAMAGES_df = roads_damaged_df[roads_damaged_df.District == DISTRICT]\n",
    "    FILTERED_DAMAGES_df['Detail_Length'] = FILTERED_DAMAGES_df['Details'].apply(lambda x: len(x))\n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.sort_values(by=['Detail_Length'])\n",
    "    \n",
    "    FILTERED_DAMAGES_df = FILTERED_DAMAGES_df.drop_duplicates(['District','Number','Date'],keep='last')\n",
    "    \n",
    "    FILTERED_DAMAGES_df['Number of Damages (Date)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('2023', x))+len(re.findall(r'\\d+/\\d+/\\d{2}\\s+',x))+len(re.findall(r'\\d+-\\d+-\\d{2}\\s+',x))+len(re.findall(r'\\d+\\.\\d+\\.\\d{2}\\s+', x)))\n",
    "    FILTERED_DAMAGES_df['Number of Damages (Long)'] = FILTERED_DAMAGES_df.Details.apply(lambda x: \n",
    "                                     len(re.findall('Long -', x)))\n",
    "        \n",
    "    \n",
    "    REVENUE_CIRCLES = [REV_CIRCLE.strip()+' -' for REV_CIRCLE in list(ASSAM_REVENUE_CIRCLES[ASSAM_REVENUE_CIRCLES.district_35==DISTRICT.upper()].revenue_ci)]\n",
    "    print(REVENUE_CIRCLES)\n",
    "    print('----')\n",
    "    FILTERED_DAMAGES_df['NumberofDamages_RevenueCircle_level'] = FILTERED_DAMAGES_df.apply(get_revcircle_damages_dict, axis=1)\n",
    "    FILTERED_DAMAGES_dfs.append(FILTERED_DAMAGES_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87003805",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_DAMAGES = pd.concat(FILTERED_DAMAGES_dfs).reset_index(drop=True)\n",
    "MASTER_DAMAGES.District = MASTER_DAMAGES.District.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa29c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_damages_revcircle_df = pd.DataFrame(columns=['District','RevenueCircle','Number of damages','Date'])\n",
    "i = 0\n",
    "for idx, row in MASTER_DAMAGES.iterrows():\n",
    "    damages_dict = row['NumberofDamages_RevenueCircle_level']\n",
    "    for key in damages_dict.keys():\n",
    "        rev_circle = key\n",
    "        no_damages = damages_dict[key]\n",
    "        \n",
    "        road_damages_revcircle_df.loc[i,'RevenueCircle'] = rev_circle\n",
    "        road_damages_revcircle_df.loc[i,'District'] = row['District']\n",
    "        road_damages_revcircle_df.loc[i,'Number of damages'] = no_damages\n",
    "        road_damages_revcircle_df.loc[i,'Date'] = row['Date']\n",
    "        i=i+1\n",
    "road_damages_revcircle_df.Date = pd.to_datetime(road_damages_revcircle_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c766531",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_damages_revcircle_df.RevenueCircle =road_damages_revcircle_df.RevenueCircle.str.strip()\n",
    "road_damages_revcircle_df.loc[road_damages_revcircle_df.RevenueCircle == 'Na', 'RevenueCircle'] = 'Na-Duar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cfcb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_damages_revcircle_df = pd.merge(road_damages_revcircle_df,\n",
    "                                ASSAM_REVENUE_CIRCLES[['district_35', 'revenue_ci','object_id']],\n",
    "                                left_on=['District', 'RevenueCircle'],\n",
    "                                right_on=['district_35', 'revenue_ci'],\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78432eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_damages_revcircle_df = road_damages_revcircle_df[['Date','object_id','revenue_ci','District','Number of damages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4088e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_damages_revcircle_df.to_csv('Data_2023/Cleaned Data/RC_FRIMS_ROADS_DAMAGED_MASTER_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33ba4b",
   "metadata": {},
   "source": [
    "# Lat-Lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9c4df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    flattened_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flattened_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened_list.append(item)\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "998423c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>District</th>\n",
       "      <th>Number</th>\n",
       "      <th>Details</th>\n",
       "      <th>state</th>\n",
       "      <th>ID</th>\n",
       "      <th>assam_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>1</td>\n",
       "      <td>Halem - At upstream ofTinikuniaon R/Bank TeaGa...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>JORHAT</td>\n",
       "      <td>1</td>\n",
       "      <td>Teok - Teok river left ring bund | Dakhin Duli...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>22</td>\n",
       "      <td>2011Jorh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-07-09</td>\n",
       "      <td>JORHAT</td>\n",
       "      <td>1</td>\n",
       "      <td>Teok - Right ring bund of river Teok | Dakhin ...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>22</td>\n",
       "      <td>2011Jorh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>BISWANATH</td>\n",
       "      <td>1</td>\n",
       "      <td>Halem - Tupung river embankment | Jogibari | S...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>24</td>\n",
       "      <td>2019Bisw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>UDALGURI</td>\n",
       "      <td>1</td>\n",
       "      <td>Udalguri - Dhansiri Irrigation Project | Vilag...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>21</td>\n",
       "      <td>2011Udal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   District  Number  \\\n",
       "25  2023-06-28  BISWANATH       1   \n",
       "26  2023-06-29     JORHAT       1   \n",
       "27  2023-07-09     JORHAT       1   \n",
       "28  2023-07-10  BISWANATH       1   \n",
       "29  2023-07-11   UDALGURI       1   \n",
       "\n",
       "                                              Details  state  ID assam_dist  \n",
       "25  Halem - At upstream ofTinikuniaon R/Bank TeaGa...  ASSAM  24   2019Bisw  \n",
       "26  Teok - Teok river left ring bund | Dakhin Duli...  ASSAM  22   2011Jorh  \n",
       "27  Teok - Right ring bund of river Teok | Dakhin ...  ASSAM  22   2011Jorh  \n",
       "28  Halem - Tupung river embankment | Jogibari | S...  ASSAM  24   2019Bisw  \n",
       "29  Udalguri - Dhansiri Irrigation Project | Vilag...  ASSAM  21   2011Udal  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data_2023/Cleaned Data/DISTRICTS_FRIMS_EMBANKMENTS_BREACHED_MASTER_2023.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8953a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates_list = []\n",
    "locs_list = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    details = row['Details']\n",
    "    long_lats = re.findall('\\d{1,2}\\.\\d{6}', details)\n",
    "    locs_list.append(long_lats)\n",
    "    #long_lats = [x for x in long_lats if float(x) != 0]\n",
    "    repeat = int(len(long_lats)/2)\n",
    "    dates = [row['Date']]*repeat\n",
    "    dates_list.append(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "170cac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = []\n",
    "latitudes = []\n",
    "\n",
    "for loc in flatten_list(locs_list):\n",
    "    if float(loc) < 80:\n",
    "        latitudes.append(loc)\n",
    "    else:\n",
    "        longitudes.append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c290f34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(longitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c38eb038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89b32a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_list(dates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f432aab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_list(locs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150a4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f29e9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "breaches_lat_lon_df = pd.DataFrame([dates_list, longitudes,latitudes]).T\n",
    "breaches_lat_lon_df.columns = ['Date', 'Longitude', 'Latitude']\n",
    "breaches_lat_lon_df.to_csv('Data_2023/Cleaned Data/LAT_LONS_FRIMS_EMBANKMENTS_BREACHED_MASTER_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acfc52b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db8082ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2023-06-11, 2023-06-11]</td>\n",
       "      <td>93.628098</td>\n",
       "      <td>26.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2023-06-12, 2023-06-12]</td>\n",
       "      <td>93.555650</td>\n",
       "      <td>27.095780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2023-06-12, 2023-06-12, 2023-06-12, 2023-06-1...</td>\n",
       "      <td>91.992661</td>\n",
       "      <td>26.440664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2023-06-12, 2023-06-12]</td>\n",
       "      <td>91.960690</td>\n",
       "      <td>26.442980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2023-06-14, 2023-06-14, 2023-06-14, 2023-06-14]</td>\n",
       "      <td>91.960690</td>\n",
       "      <td>26.442980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2023-06-15, 2023-06-15]</td>\n",
       "      <td>93.691218</td>\n",
       "      <td>26.900444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2023-06-16, 2023-06-16, 2023-06-16, 2023-06-16]</td>\n",
       "      <td>94.006159</td>\n",
       "      <td>17.156999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2023-06-16, 2023-06-16, 2023-06-16, 2023-06-16]</td>\n",
       "      <td>90.753727</td>\n",
       "      <td>26.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[2023-06-17, 2023-06-17]</td>\n",
       "      <td>91.776100</td>\n",
       "      <td>26.711700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2023-06-17, 2023-06-17]</td>\n",
       "      <td>91.986521</td>\n",
       "      <td>26.562401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2023-06-17, 2023-06-17]</td>\n",
       "      <td>91.998531</td>\n",
       "      <td>26.598621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[2023-06-17, 2023-06-17, 2023-06-17, 2023-06-17]</td>\n",
       "      <td>92.710210</td>\n",
       "      <td>26.717130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[2023-06-20, 2023-06-20]</td>\n",
       "      <td>92.717367</td>\n",
       "      <td>26.106437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[2023-06-21, 2023-06-21, 2023-06-21, 2023-06-2...</td>\n",
       "      <td>91.995900</td>\n",
       "      <td>26.443300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[2023-06-21, 2023-06-21]</td>\n",
       "      <td>91.992800</td>\n",
       "      <td>26.419400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[2023-06-22, 2023-06-22, 2023-06-22, 2023-06-2...</td>\n",
       "      <td>91.758400</td>\n",
       "      <td>26.700700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[2023-06-22, 2023-06-22]</td>\n",
       "      <td>91.357248</td>\n",
       "      <td>26.540695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[2023-06-22, 2023-06-22]</td>\n",
       "      <td>91.362613</td>\n",
       "      <td>26.531607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[2023-06-22, 2023-06-22]</td>\n",
       "      <td>91.362613</td>\n",
       "      <td>26.531608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[2023-06-23, 2023-06-23]</td>\n",
       "      <td>91.159080</td>\n",
       "      <td>26.536302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[2023-06-24, 2023-06-24, 2023-06-24, 2023-06-2...</td>\n",
       "      <td>91.142550</td>\n",
       "      <td>26.452241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[2023-06-25, 2023-06-25, 2023-06-25, 2023-06-2...</td>\n",
       "      <td>91.142560</td>\n",
       "      <td>26.452241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[2023-06-26, 2023-06-26, 2023-06-26, 2023-06-26]</td>\n",
       "      <td>91.261245</td>\n",
       "      <td>26.505215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[2023-06-27, 2023-06-27, 2023-06-27, 2023-06-27]</td>\n",
       "      <td>91.240337</td>\n",
       "      <td>26.503750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[2023-06-28, 2023-06-28]</td>\n",
       "      <td>91.227382</td>\n",
       "      <td>26.478453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[2023-06-28, 2023-06-28]</td>\n",
       "      <td>91.155950</td>\n",
       "      <td>26.536513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[2023-06-29, 2023-06-29]</td>\n",
       "      <td>93.610147</td>\n",
       "      <td>26.885536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[2023-07-09, 2023-07-09]</td>\n",
       "      <td>91.993733</td>\n",
       "      <td>26.538391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[2023-07-10, 2023-07-10]</td>\n",
       "      <td>93.609539</td>\n",
       "      <td>26.886682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[2023-07-11, 2023-07-11]</td>\n",
       "      <td>91.994520</td>\n",
       "      <td>26.444710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>91.994520</td>\n",
       "      <td>26.444710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>91.994500</td>\n",
       "      <td>26.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>91.994520</td>\n",
       "      <td>26.444710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>None</td>\n",
       "      <td>91.994520</td>\n",
       "      <td>26.444710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>91.994520</td>\n",
       "      <td>26.444710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>None</td>\n",
       "      <td>91.992540</td>\n",
       "      <td>26.537680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>None</td>\n",
       "      <td>91.994520</td>\n",
       "      <td>26.444710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>None</td>\n",
       "      <td>91.994520</td>\n",
       "      <td>26.444710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>None</td>\n",
       "      <td>94.457179</td>\n",
       "      <td>26.771686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>None</td>\n",
       "      <td>94.454895</td>\n",
       "      <td>26.776590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>None</td>\n",
       "      <td>92.753871</td>\n",
       "      <td>26.897990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>None</td>\n",
       "      <td>93.481104</td>\n",
       "      <td>26.933649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>None</td>\n",
       "      <td>94.396660</td>\n",
       "      <td>26.839715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>94.398732</td>\n",
       "      <td>26.840768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>None</td>\n",
       "      <td>93.508465</td>\n",
       "      <td>26.871768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>None</td>\n",
       "      <td>92.005296</td>\n",
       "      <td>26.728898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Date  Longitude   Latitude\n",
       "0                            [2023-06-11, 2023-06-11]  93.628098  26.886123\n",
       "1                            [2023-06-12, 2023-06-12]  93.555650  27.095780\n",
       "2   [2023-06-12, 2023-06-12, 2023-06-12, 2023-06-1...  91.992661  26.440664\n",
       "3                            [2023-06-12, 2023-06-12]  91.960690  26.442980\n",
       "4    [2023-06-14, 2023-06-14, 2023-06-14, 2023-06-14]  91.960690  26.442980\n",
       "5                            [2023-06-15, 2023-06-15]  93.691218  26.900444\n",
       "6    [2023-06-16, 2023-06-16, 2023-06-16, 2023-06-16]  94.006159  17.156999\n",
       "7    [2023-06-16, 2023-06-16, 2023-06-16, 2023-06-16]  90.753727  26.020408\n",
       "8                            [2023-06-17, 2023-06-17]  91.776100  26.711700\n",
       "9                            [2023-06-17, 2023-06-17]  91.986521  26.562401\n",
       "10                           [2023-06-17, 2023-06-17]  91.998531  26.598621\n",
       "11   [2023-06-17, 2023-06-17, 2023-06-17, 2023-06-17]  92.710210  26.717130\n",
       "12                           [2023-06-20, 2023-06-20]  92.717367  26.106437\n",
       "13  [2023-06-21, 2023-06-21, 2023-06-21, 2023-06-2...  91.995900  26.443300\n",
       "14                           [2023-06-21, 2023-06-21]  91.992800  26.419400\n",
       "15  [2023-06-22, 2023-06-22, 2023-06-22, 2023-06-2...  91.758400  26.700700\n",
       "16                           [2023-06-22, 2023-06-22]  91.357248  26.540695\n",
       "17                           [2023-06-22, 2023-06-22]  91.362613  26.531607\n",
       "18                           [2023-06-22, 2023-06-22]  91.362613  26.531608\n",
       "19                           [2023-06-23, 2023-06-23]  91.159080  26.536302\n",
       "20  [2023-06-24, 2023-06-24, 2023-06-24, 2023-06-2...  91.142550  26.452241\n",
       "21  [2023-06-25, 2023-06-25, 2023-06-25, 2023-06-2...  91.142560  26.452241\n",
       "22   [2023-06-26, 2023-06-26, 2023-06-26, 2023-06-26]  91.261245  26.505215\n",
       "23   [2023-06-27, 2023-06-27, 2023-06-27, 2023-06-27]  91.240337  26.503750\n",
       "24                           [2023-06-28, 2023-06-28]  91.227382  26.478453\n",
       "25                           [2023-06-28, 2023-06-28]  91.155950  26.536513\n",
       "26                           [2023-06-29, 2023-06-29]  93.610147  26.885536\n",
       "27                           [2023-07-09, 2023-07-09]  91.993733  26.538391\n",
       "28                           [2023-07-10, 2023-07-10]  93.609539  26.886682\n",
       "29                           [2023-07-11, 2023-07-11]  91.994520  26.444710\n",
       "30                                               None  91.994520  26.444710\n",
       "31                                               None  91.994500  26.444700\n",
       "32                                               None  91.994520  26.444710\n",
       "33                                               None  91.994520  26.444710\n",
       "34                                               None  91.994520  26.444710\n",
       "35                                               None  91.992540  26.537680\n",
       "36                                               None  91.994520  26.444710\n",
       "37                                               None  91.994520  26.444710\n",
       "38                                               None  94.457179  26.771686\n",
       "39                                               None  94.454895  26.776590\n",
       "40                                               None  92.753871  26.897990\n",
       "41                                               None  93.481104  26.933649\n",
       "42                                               None  94.396660  26.839715\n",
       "43                                               None  94.398732  26.840768\n",
       "44                                               None  93.508465  26.871768\n",
       "45                                               None  92.005296  26.728898"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breaches_lat_lon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9e974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
