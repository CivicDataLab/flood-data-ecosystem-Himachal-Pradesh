{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3728c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import pygsheets\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124a65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assam_districts = gpd.read_file('Data/Assam_Maps/assam_district_35.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d798b8f",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "* [Functions to be used](#functions)\n",
    "* [Download PDFs](#download)\n",
    "* [Scraper for infrastructure damage tables](#infradamages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fc316",
   "metadata": {},
   "source": [
    "## Functions <a class=\"anchor\" id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a34c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence Matcher helps us get the metric that measures how two strings are matching\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "#We will write a function that gives us matching score between two strings a and b. Higher the score,better the match\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81dbf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One FRIMS PDF has multiple tables that have to be scraped.\n",
    "## The following functions are used to isolate the tables based on their categories. \n",
    "def get_table_start_index(FRIMS_DF, slug_list):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param slug_list: A list of keywords used to identify a particular table in the PDF.\n",
    "    \n",
    "    :return: Returns the index of the first row of the intended table.\n",
    "    '''\n",
    "    TABLE_START_INDEX = FRIMS_DF[FRIMS_DF.iloc[:,0].isin(slug_list)].index.values[0]\n",
    "    return TABLE_START_INDEX\n",
    "\n",
    "def get_table_end_index(FRIMS_DF, TABLE_START_INDEX):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param TABLE_START_INDEX: Once the index of a table's first row is found, it is passed into this function.\n",
    "    \n",
    "    :return: Returns the index of the last row of the intended table.\n",
    "    '''\n",
    "    for index,row in FRIMS_DF[TABLE_START_INDEX+1:].fillna('').iterrows():\n",
    "        if row[0]=='':\n",
    "            continue\n",
    "        else:\n",
    "            TABLE_END_INDEX = index\n",
    "            return TABLE_END_INDEX\n",
    "            break\n",
    "    return TABLE_START_INDEX+100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3070b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param TABLE_START_INDEX: Once the index of a table's first row is found, it is passed into this function.\n",
    "    :param TABLE_END_INDEX: Once the index of a table's last row is found, it is passed into this function.\n",
    "    \n",
    "    :return: Returns the filtered table between the indices passed, after cleaning it.\n",
    "    '''\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_DF.loc[TABLE_START_INDEX:TABLE_END_INDEX-1,:].reset_index(drop=True)\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_INFRA_DAMAGES_DF.replace(r'\\n','',regex=True)\n",
    "    \n",
    "    FRIMS_INFRA_DAMAGES_DF.columns=FRIMS_INFRA_DAMAGES_DF.iloc[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_INFRA_DAMAGES_DF.loc[1:,:]\n",
    "    \n",
    "    return FRIMS_INFRA_DAMAGES_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5f917",
   "metadata": {},
   "source": [
    "## Download PDFs <a class=\"anchor\" id=\"download\"></a>\n",
    "\n",
    "Download all PDFs from [FRIMS](http://www.asdma.gov.in/reports.html) portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf924bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_01.06.2023.pdf\n",
      "02.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_02.06.2023.pdf\n",
      "03.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_03.06.2023.pdf\n",
      "04.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_04.06.2023.pdf\n",
      "05.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_05.06.2023.pdf\n",
      "06.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_06.06.2023.pdf\n",
      "07.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_07.06.2023.pdf\n",
      "08.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_08.06.2023.pdf\n",
      "09.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_09.06.2023.pdf\n",
      "10.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_10.06.2023.pdf\n",
      "11.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_11.06.2023.pdf\n",
      "12.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_12.06.2023.pdf\n",
      "13.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_13.06.2023.pdf\n",
      "14.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_14.06.2023.pdf\n",
      "15.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_15.06.2023.pdf\n",
      "16.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_16.06.2023.pdf\n",
      "17.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_17.06.2023.pdf\n",
      "18.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_18.06.2023.pdf\n",
      "19.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_19.06.2023.pdf\n",
      "20.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_20.06.2023.pdf\n",
      "21.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_21.06.2023.pdf\n",
      "22.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_22.06.2023.pdf\n",
      "23.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_23.06.2023.pdf\n",
      "24.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_24.06.2023.pdf\n",
      "25.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_25.06.2023.pdf\n",
      "26.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_26.06.2023.pdf\n",
      "27.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_27.06.2023.pdf\n",
      "28.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_28.06.2023.pdf\n",
      "29.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_29.06.2023.pdf\n",
      "30.06.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_30.06.2023.pdf\n",
      "01.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_01.07.2023.pdf\n",
      "02.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_02.07.2023.pdf\n",
      "03.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_03.07.2023.pdf\n",
      "04.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_04.07.2023.pdf\n",
      "05.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_05.07.2023.pdf\n",
      "06.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_06.07.2023.pdf\n",
      "07.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_07.07.2023.pdf\n",
      "08.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_08.07.2023.pdf\n",
      "09.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_09.07.2023.pdf\n",
      "10.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_10.07.2023.pdf\n",
      "11.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_11.07.2023.pdf\n",
      "12.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_12.07.2023.pdf\n",
      "13.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_13.07.2023.pdf\n",
      "14.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_14.07.2023.pdf\n",
      "15.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_15.07.2023.pdf\n",
      "16.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_16.07.2023.pdf\n",
      "17.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_17.07.2023.pdf\n",
      "18.07.2023\n",
      "https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_18.07.2023.pdf\n"
     ]
    }
   ],
   "source": [
    "for month in range(6,8):\n",
    "    if month in [6]:\n",
    "        max_date=31\n",
    "        min_date=1\n",
    "    elif month in [7]:\n",
    "        max_date=19\n",
    "        min_date=1\n",
    "\n",
    "\n",
    "    for day in range(min_date,max_date):\n",
    "        date = str(day)+'-'+str(month)+'-'+'2023'\n",
    "        if type(date)==str:\n",
    "            date = datetime.strptime(date, '%d-%m-%Y').date()\n",
    "        else:\n",
    "            date = date + timedelta(days=-1)\n",
    "        \n",
    "        if date.month<10:\n",
    "            date_month = '0'+str(date.month)\n",
    "        else:\n",
    "            date_month = str(date.month)\n",
    "        \n",
    "        if date.day<10:\n",
    "            date_day = '0'+str(date.day)\n",
    "        else:\n",
    "            date_day = str(date.day)\n",
    "        \n",
    "        date_string = date_day+'.'+date_month+'.'+str(date.year)\n",
    "        print(date_string)\n",
    "        \n",
    "        daily_report_url = 'https://www.asdma.gov.in/pdf/flood_report/2023/Daily_Flood_Report_'+date_string+'.pdf'\n",
    "        print(daily_report_url)\n",
    "        urllib.request.urlretrieve(daily_report_url, r\"FRIMS_Reports_2023/FRIMS_\"+date_string+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9702c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRIMS_Reports_2023/FRIMS_27.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_04.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_13.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_07.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_24.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_01.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_06.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_26.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_16.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_16.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_02.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_10.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_18.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_05.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_08.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_04.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_11.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_23.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_21.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_03.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_30.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_06.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_18.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_14.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_17.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_15.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_14.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_09.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_03.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_15.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_09.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_01.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_08.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_29.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_07.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_28.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_13.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_19.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_20.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_05.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_10.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_02.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_12.07.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_25.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_11.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_22.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_17.06.2023.pdf\n",
      "FRIMS_Reports_2023/FRIMS_12.06.2023.pdf\n"
     ]
    }
   ],
   "source": [
    "frims_pdfs = glob.glob('FRIMS_Reports_2023/*.pdf')\n",
    "for pdf in frims_pdfs:\n",
    "    print(pdf)\n",
    "    date_string = pdf.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    tables = camelot.read_pdf(pdf,pages='all')\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(0,len(tables)):\n",
    "        df = pd.concat([df,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "    df.to_csv(\"FRIMS_Reports_2023/FRIMS_\"+date_string+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3354969",
   "metadata": {},
   "source": [
    "# INFRA DAMAGES <a class=\"anchor\" id=\"infradamages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "060df38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for file in glob.glob('FRIMS_Reports_2023/FRIMS_*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "\n",
    "issue_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa83751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_lists = [['infrastructure damaged - road','infrastructure damaged - roads'],\n",
    "              ['infrastructure damaged - embankments affected','infrastructure damaged - embankment affected'],\n",
    "              ['infrastructure damaged - bridge','infrastructure damaged - bridges'],\n",
    "              ['infrastructure damaged - embankments breached','infrastructure damaged - embankment breached'],\n",
    "              ]\n",
    "\n",
    "folder_slug_dict = dict()\n",
    "folder_slug_dict[0] ='FRIMS_ROADS_DAMAGED'\n",
    "folder_slug_dict[1] ='FRIMS_EMBANKMENTS_AFFECTED'\n",
    "folder_slug_dict[2] ='FRIMS_BRIDGES_DAMAGED'\n",
    "folder_slug_dict[3] ='FRIMS_EMBANKMENTS_BREACHED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f67c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_issue_dates = []\n",
    "embankment_affected_issue_dates = []\n",
    "bridge_issue_dates = []\n",
    "embankment_breached_issue_dates = []\n",
    "\n",
    "issues_dates = [road_issue_dates,\n",
    "                embankment_affected_issue_dates,\n",
    "               bridge_issue_dates,\n",
    "                embankment_breached_issue_dates,\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad32ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  27-06-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "04.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  04-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  04-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  04-07-2023\n",
      "----\n",
      "13.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  13-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  13-07-2023\n",
      "----\n",
      "07.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  07.06.2023\n",
      "----\n",
      "24.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "01.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  01-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  01-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  01-07-2023\n",
      "----\n",
      "06.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  06.06.2023\n",
      "----\n",
      "26.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "16.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  16-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "16.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  16-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  16-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  16-07-2023\n",
      "----\n",
      "02.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  02.07.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  02.07.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  02.07.2023\n",
      "----\n",
      "10.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  10.06.2023\n",
      "----\n",
      "18.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  18-06-2023\n",
      "----\n",
      "05.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  05.06.2023\n",
      "----\n",
      "08.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  08.06.2023\n",
      "----\n",
      "04.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  04.06.2023\n",
      "----\n",
      "11.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "23.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6371/1982773773.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "21.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "03.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  03.06.2023\n",
      "----\n",
      "30.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  30-06-2023\n",
      "----\n",
      "06.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  06-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  06-07-2023\n",
      "----\n",
      "18.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  18-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  18-07-2023\n",
      "----\n",
      "14.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  14-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  14-07-2023\n",
      "----\n",
      "17.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  17-07-2023\n",
      "----\n",
      "15.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  15-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  15-07-2023\n",
      "----\n",
      "14.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "09.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  09.06.2023\n",
      "----\n",
      "03.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  03-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  03-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  03-07-2023\n",
      "----\n",
      "15.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  15-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "09.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  09-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  09-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "01.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  01.06.2023\n",
      "----\n",
      "08.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  08-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  08-07-2023\n",
      "----\n",
      "29.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  29-06-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  29-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "07.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  07-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  07-07-2023\n",
      "----\n",
      "28.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  28.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  28.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "13.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  13-06-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  13-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  13-06-2023\n",
      "----\n",
      "19.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  19-06-2023\n",
      "----\n",
      "20.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "05.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  05-07-2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  05-07-2023\n",
      "----\n",
      "10.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "02.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  02.06.2023\n",
      "----\n",
      "12.07.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  12-07-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  12-07-2023\n",
      "----\n",
      "25.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "11.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  11-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "22.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "17.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "12.06.2023\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  12-06-2023\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for date in dates:    \n",
    "    print(date)\n",
    "    FRIMS_csv_file = r\"FRIMS_Reports_2023/FRIMS_\"+date+\".csv\"\n",
    "    \n",
    "    \n",
    "    FRIMS_DF = pd.read_csv(FRIMS_csv_file)\n",
    "    \n",
    "    FRIMS_DF.iloc[:,0] = FRIMS_DF.iloc[:,0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_DF.iloc[:,0] = FRIMS_DF.iloc[:,0].str.lower()\n",
    "    \n",
    "    for list_number, slug_list in enumerate(slug_lists):\n",
    "        folder_slug = folder_slug_dict[list_number]\n",
    "        print(folder_slug)\n",
    "        \n",
    "        try:\n",
    "            TABLE_START_INDEX = get_table_start_index(FRIMS_DF, slug_list)\n",
    "        except:\n",
    "            issues_dates[list_number].append(date)\n",
    "            print('Issue with infra damages table - Row header across multiple pages')\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        if folder_slug=='FRIMS_URBANFLOOD':\n",
    "            TABLE_END_INDEX = TABLE_START_INDEX+100\n",
    "        else:\n",
    "            TABLE_END_INDEX = get_table_end_index(FRIMS_DF, TABLE_START_INDEX)\n",
    "\n",
    "        if TABLE_END_INDEX-1 <= TABLE_START_INDEX:\n",
    "            print(\"No data for: \",date)\n",
    "            #done_dates.append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:   \n",
    "            FRIMS_INFRA_DAMAGES_DF = extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX-1)\n",
    "        except:\n",
    "            print(\"No dataa for: \",date)\n",
    "            #issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            col_name = FRIMS_INFRA_DAMAGES_DF.columns[1]\n",
    "            FRIMS_INFRA_DAMAGES_DF[col_name] = FRIMS_INFRA_DAMAGES_DF[col_name].replace('',None).fillna(method='ffill')\n",
    "            g = FRIMS_INFRA_DAMAGES_DF.groupby(col_name)['Details'].transform(lambda x: ' '.join(x))\n",
    "        except:\n",
    "            print('Issues with cleaning and combining')\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        FRIMS_INFRA_DAMAGES_DF['Details'] = g\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF.drop_duplicates()\n",
    "        \n",
    "        \n",
    "        date = date.replace('.','-')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF_CLEANED[['Date', col_name, 'Number', 'Details']]\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.columns = ['Date', 'District', 'Number', 'Details']\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF_CLEANED[FRIMS_INFRA_DAMAGES_DF_CLEANED['Number'].notna()]\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.reset_index(drop=True).to_csv(r'Data_2023/Scraped Data/'+folder_slug+r'/'+folder_slug+'_'+str(date)+'.csv', index=False)\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258e2557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRIMS_ROADS_DAMAGED</th>\n",
       "      <th>FRIMS_EMBANKMENTS_AFFECTED</th>\n",
       "      <th>FRIMS_BRIDGES_DAMAGED</th>\n",
       "      <th>FRIMS_EMBANKMENTS_BREACHED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.07.2023</td>\n",
       "      <td>12-07-2023</td>\n",
       "      <td>26-06-2023</td>\n",
       "      <td>24-06-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.06.2023</td>\n",
       "      <td>None</td>\n",
       "      <td>30-06-2023</td>\n",
       "      <td>29-06-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.07.2023</td>\n",
       "      <td>None</td>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FRIMS_ROADS_DAMAGED FRIMS_EMBANKMENTS_AFFECTED FRIMS_BRIDGES_DAMAGED  \\\n",
       "0          02.07.2023                 12-07-2023            26-06-2023   \n",
       "1          28.06.2023                       None            30-06-2023   \n",
       "2          10.07.2023                       None            05-07-2023   \n",
       "\n",
       "  FRIMS_EMBANKMENTS_BREACHED  \n",
       "0                 24-06-2023  \n",
       "1                 29-06-2023  \n",
       "2                       None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_df = pd.DataFrame(issues_dates).T\n",
    "issues_df.columns = folder_slug_dict.values()\n",
    "issues_df\n",
    "\n",
    "#Add this manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06abbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_slug in folder_slug_dict.values():\n",
    "    scraped_files_daily = glob.glob(r'Data_2023/Scraped Data/{}/*.csv'.format(folder_slug))\n",
    "    \n",
    "    dfs = []\n",
    "    for file in scraped_files_daily:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    FRIMS_DAMAGES = pd.concat(dfs)\n",
    "    FRIMS_DAMAGES['Date'] = pd.to_datetime(FRIMS_DAMAGES['Date'],format='%d-%m-%Y')\n",
    "    FRIMS_DAMAGES = FRIMS_DAMAGES.sort_values(by='Date')\n",
    "    \n",
    "    FRIMS_DAMAGES['District'] = FRIMS_DAMAGES.District.str.replace('Dima-Hasao','Dima Hasao',regex=True)\n",
    "    FRIMS_DAMAGES['District'] = FRIMS_DAMAGES.District.str.upper()\n",
    "    \n",
    "    FRIMS_DAMAGES = pd.merge(FRIMS_DAMAGES,assam_districts, how='left').drop('geometry', axis=1)\n",
    "\n",
    "    FRIMS_DAMAGES.drop_duplicates().dropna().to_csv('Data_2023/Cleaned Data/DISTRICTS_{}_MASTER_2023.csv'.format(folder_slug), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc2b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
