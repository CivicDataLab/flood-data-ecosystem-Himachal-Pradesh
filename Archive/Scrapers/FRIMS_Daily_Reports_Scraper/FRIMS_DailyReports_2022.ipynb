{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e70312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import pygsheets\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d210763",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "* [Functions to be used](#functions)\n",
    "* [Download PDFs](#download)\n",
    "* [Sample PDF Scraper](#sample)\n",
    "* [Scraper for relief distributed, houses and human lives lost](#misc)\n",
    "* [Scraper for Animals affected and washed away tables](#animals)\n",
    "* [Scraper for Other Damages tables - other infra, urban flood, landslide, wildlife, erosion](#otherdamages)\n",
    "* [Scraper for infrastructure damage tables](#infradamages)\n",
    "* [Scraper for population, crop and relelif camp tables](#population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f95428",
   "metadata": {},
   "source": [
    "## Functions <a class=\"anchor\" id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75f2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence Matcher helps us get the metric that measures how two strings are matching\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "#We will write a function that gives us matching score between two strings a and b. Higher the score,better the match\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7f6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One FRIMS PDF has multiple tables that have to be scraped. The following functions are used to isolate the tables based on their categories. \n",
    "def get_table_start_index(FRIMS_DF, slug_list):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param slug_list: A list of keywords used to identify a particular table in the PDF.\n",
    "    \n",
    "    :return: Returns the index of the first row of the intended table.\n",
    "    '''\n",
    "    TABLE_START_INDEX = FRIMS_DF[FRIMS_DF[0].isin(slug_list)].index.values[0]\n",
    "    return TABLE_START_INDEX\n",
    "\n",
    "def get_table_end_index(FRIMS_DF, TABLE_START_INDEX):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param TABLE_START_INDEX: Once the index of a table's first row is found, it is passed into this function.\n",
    "    \n",
    "    :return: Returns the index of the last row of the intended table.\n",
    "    '''\n",
    "    for index,row in FRIMS_DF[TABLE_START_INDEX+1:].iterrows():\n",
    "        if row[0]=='':\n",
    "            continue\n",
    "        else:\n",
    "            TABLE_END_INDEX = index\n",
    "            return TABLE_END_INDEX\n",
    "            break\n",
    "    return TABLE_START_INDEX+100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f2d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX):\n",
    "    '''\n",
    "    :param FRIMS_DF: The FRIMS Data Frame of a particular date.\n",
    "    :param TABLE_START_INDEX: Once the index of a table's first row is found, it is passed into this function.\n",
    "    :param TABLE_END_INDEX: Once the index of a table's last row is found, it is passed into this function.\n",
    "    \n",
    "    :return: Returns the filtered table between the indices passed, after cleaning it.\n",
    "    '''\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_DF.loc[TABLE_START_INDEX:TABLE_END_INDEX-1,:].reset_index(drop=True)\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_INFRA_DAMAGES_DF.replace(r'\\n','',regex=True)\n",
    "    \n",
    "    FRIMS_INFRA_DAMAGES_DF.columns=FRIMS_INFRA_DAMAGES_DF.iloc[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_INFRA_DAMAGES_DF = FRIMS_INFRA_DAMAGES_DF.loc[1:,:]\n",
    "    \n",
    "    return FRIMS_INFRA_DAMAGES_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df2b8f",
   "metadata": {},
   "source": [
    "## Download PDFs <a class=\"anchor\" id=\"download\"></a>\n",
    "\n",
    "Download all PDFs from [FRIMS](http://www.asdma.gov.in/reports.html) portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f83347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_01.08.2022.pdf\n",
      "02.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_02.08.2022.pdf\n",
      "03.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_03.08.2022.pdf\n",
      "04.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_04.08.2022.pdf\n",
      "05.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_05.08.2022.pdf\n",
      "06.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_06.08.2022.pdf\n",
      "07.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_07.08.2022.pdf\n",
      "08.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_08.08.2022.pdf\n",
      "09.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_09.08.2022.pdf\n",
      "10.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_10.08.2022.pdf\n",
      "11.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_11.08.2022.pdf\n",
      "12.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_12.08.2022.pdf\n",
      "13.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_13.08.2022.pdf\n",
      "14.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_14.08.2022.pdf\n",
      "15.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_15.08.2022.pdf\n",
      "16.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_16.08.2022.pdf\n",
      "17.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_17.08.2022.pdf\n",
      "18.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_18.08.2022.pdf\n",
      "19.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_19.08.2022.pdf\n",
      "20.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_20.08.2022.pdf\n",
      "21.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_21.08.2022.pdf\n",
      "22.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_22.08.2022.pdf\n",
      "23.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_23.08.2022.pdf\n",
      "24.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_24.08.2022.pdf\n",
      "25.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_25.08.2022.pdf\n",
      "26.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_26.08.2022.pdf\n",
      "27.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_27.08.2022.pdf\n",
      "28.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_28.08.2022.pdf\n",
      "29.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_29.08.2022.pdf\n",
      "30.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_30.08.2022.pdf\n",
      "31.08.2022\n",
      "http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_31.08.2022.pdf\n"
     ]
    }
   ],
   "source": [
    "for month in range(8,9):\n",
    "    if month in [8,10]:\n",
    "        max_date=32\n",
    "        min_date=1\n",
    "    elif month in [9]:\n",
    "        max_date=31\n",
    "        min_date=1\n",
    "\n",
    "\n",
    "    for day in range(min_date,max_date):\n",
    "        date = str(day)+'-'+str(month)+'-'+'2022'\n",
    "        if type(date)==str:\n",
    "            date = datetime.strptime(date, '%d-%m-%Y').date()\n",
    "        else:\n",
    "            date = date + timedelta(days=-1)\n",
    "        \n",
    "        if date.month<10:\n",
    "            date_month = '0'+str(date.month)\n",
    "        else:\n",
    "            date_month = str(date.month)\n",
    "        \n",
    "        if date.day<10:\n",
    "            date_day = '0'+str(date.day)\n",
    "        else:\n",
    "            date_day = str(date.day)\n",
    "        \n",
    "        date_string = date_day+'.'+date_month+'.'+str(date.year)\n",
    "        print(date_string)\n",
    "        \n",
    "        daily_report_url = 'http://www.asdma.gov.in/pdf/flood_report/2022/Daily_Flood_Report_'+date_string+'.pdf'\n",
    "        print(daily_report_url)\n",
    "        urllib.request.urlretrieve(daily_report_url, r\"D:/Projects/assam-tender-scraper/FRIMS_Daily_Reports_Scraper/FRIMS_Reports/FRIMS_\"+date_string+\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a8eb9",
   "metadata": {},
   "source": [
    "## Sample PDF scraper <a class=\"anchor\" id=\"sample\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f53ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_5408/1159762544.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[0] = df[0].str.replace(r'\\n','')\n"
     ]
    }
   ],
   "source": [
    "date = '11.10.2022'\n",
    "pdf_file = r\"FRIMS_Reports/FRIMS_\"+date+\".pdf\"\n",
    "tables = camelot.read_pdf(pdf_file,pages='all')\n",
    "df = pd.DataFrame()\n",
    "for i in range(0,len(tables)):\n",
    "    df = pd.concat([df,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "df[0] = df[0].str.replace(r'\\n','')\n",
    "df[0] = df[0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f73b3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slug_list = ['relief distributed'] # This slug is to identify the relief distributed table in the PDF\n",
    "TABLE_START_INDEX = df[df[0].isin(slug_list)].index.values[0]\n",
    "TABLE_START_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b461ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index,row in df[TABLE_START_INDEX+1:].iterrows():\n",
    "    if row[0]=='':\n",
    "        continue\n",
    "    else:\n",
    "        TABLE_END_INDEX = index\n",
    "        break\n",
    "TABLE_END_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbd0125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>relief distributed</td>\n",
       "      <td>District</td>\n",
       "      <td>Rice (in Q)</td>\n",
       "      <td>Dal (in Q)</td>\n",
       "      <td>Salt (in Q)</td>\n",
       "      <td>M. Oil (in L)</td>\n",
       "      <td>Cattle Feed - Green Fooder (in Q)</td>\n",
       "      <td>Cattle Feed - Wheat Bran (in Q)</td>\n",
       "      <td>Cattle Feed - Rice Bran (in Q)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td>Dhemaji</td>\n",
       "      <td>111.21</td>\n",
       "      <td>20.18</td>\n",
       "      <td>6.05</td>\n",
       "      <td>605.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td></td>\n",
       "      <td>Total</td>\n",
       "      <td>111.21</td>\n",
       "      <td>20.18</td>\n",
       "      <td>6.05</td>\n",
       "      <td>605.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1            2           3            4   \\\n",
       "40  relief distributed  District  Rice (in Q)  Dal (in Q)  Salt (in Q)   \n",
       "41                       Dhemaji       111.21       20.18         6.05   \n",
       "42                         Total       111.21       20.18         6.05   \n",
       "\n",
       "               5                                  6   \\\n",
       "40  M. Oil (in L)  Cattle Feed - Green Fooder (in Q)   \n",
       "41         605.00                               0.00   \n",
       "42         605.00                               0.00   \n",
       "\n",
       "                                 7                               8  9  10  \n",
       "40  Cattle Feed - Wheat Bran (in Q)  Cattle Feed - Rice Bran (in Q)        \n",
       "41                             0.00                            0.00        \n",
       "42                             0.00                            0.00        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.loc[TABLE_START_INDEX:TABLE_END_INDEX-1,:]\n",
    "df_filtered = df_filtered.replace(r'\\n','',regex=True)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef0518f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relief distributed</th>\n",
       "      <th>District</th>\n",
       "      <th>Rice (in Q)</th>\n",
       "      <th>Dal (in Q)</th>\n",
       "      <th>Salt (in Q)</th>\n",
       "      <th>M. Oil (in L)</th>\n",
       "      <th>Cattle Feed - Green Fooder (in Q)</th>\n",
       "      <th>Cattle Feed - Wheat Bran (in Q)</th>\n",
       "      <th>Cattle Feed - Rice Bran (in Q)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Dhemaji</td>\n",
       "      <td>111.21</td>\n",
       "      <td>20.18</td>\n",
       "      <td>6.05</td>\n",
       "      <td>605.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Total</td>\n",
       "      <td>111.21</td>\n",
       "      <td>20.18</td>\n",
       "      <td>6.05</td>\n",
       "      <td>605.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 relief distributed District Rice (in Q) Dal (in Q) Salt (in Q)  \\\n",
       "1                     Dhemaji      111.21      20.18        6.05   \n",
       "2                       Total      111.21      20.18        6.05   \n",
       "\n",
       "0 M. Oil (in L) Cattle Feed - Green Fooder (in Q)  \\\n",
       "1        605.00                              0.00   \n",
       "2        605.00                              0.00   \n",
       "\n",
       "0 Cattle Feed - Wheat Bran (in Q) Cattle Feed - Rice Bran (in Q)      \n",
       "1                            0.00                           0.00      \n",
       "2                            0.00                           0.00      "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.loc[TABLE_START_INDEX:TABLE_END_INDEX-1,:].reset_index(drop=True)\n",
    "df_filtered.columns=df_filtered.iloc[0].str.replace(r'\\n', '', regex=True)\n",
    "df_filtered = df_filtered.loc[1:,:]\n",
    "\n",
    "for column in df_filtered.columns:\n",
    "    df_filtered[column] = df_filtered[column].replace(r'\\n', '', regex=True)\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c7e2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relief distributed</th>\n",
       "      <th>District</th>\n",
       "      <th>Rice (in Q)</th>\n",
       "      <th>Dal (in Q)</th>\n",
       "      <th>Salt (in Q)</th>\n",
       "      <th>M. Oil (in L)</th>\n",
       "      <th>Cattle Feed - Green Fooder (in Q)</th>\n",
       "      <th>Cattle Feed - Wheat Bran (in Q)</th>\n",
       "      <th>Cattle Feed - Rice Bran (in Q)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Dhemaji</td>\n",
       "      <td>111.21</td>\n",
       "      <td>20.18</td>\n",
       "      <td>6.05</td>\n",
       "      <td>605.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Total</td>\n",
       "      <td>111.21</td>\n",
       "      <td>20.18</td>\n",
       "      <td>6.05</td>\n",
       "      <td>605.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 relief distributed District Rice (in Q) Dal (in Q) Salt (in Q)  \\\n",
       "1                     Dhemaji      111.21      20.18        6.05   \n",
       "2                       Total      111.21      20.18        6.05   \n",
       "\n",
       "0 M. Oil (in L) Cattle Feed - Green Fooder (in Q)  \\\n",
       "1        605.00                              0.00   \n",
       "2        605.00                              0.00   \n",
       "\n",
       "0 Cattle Feed - Wheat Bran (in Q) Cattle Feed - Rice Bran (in Q)      \n",
       "1                            0.00                           0.00      \n",
       "2                            0.00                           0.00      "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['District'] = df_filtered['District'].replace('',None).fillna(method='bfill')\n",
    "\n",
    "#This code snippet is useful when there is any column in the table that has multiple rows per district.\n",
    "#g = df_filtered.groupby('District')['Details'].transform(lambda x: ' '.join(x))\n",
    "#df_filtered['Details'] = g\n",
    "df_filtered.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e882d2",
   "metadata": {},
   "source": [
    "## MISC <a class=\"anchor\" id=\"misc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86710123",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for file in glob.glob(r'FRIMS_Reports/FRIMS_*.08*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "\n",
    "# Store PDFs that throw an error in this list.\n",
    "issue_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11a97025",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_lists = [['relief distributed'],\n",
    "              ['relief distributed others'],\n",
    "              ['rescue operation'],\n",
    "              ['houses damaged','house damaged'],\n",
    "              ['human lives lost - confirmed'],\n",
    "              ['human lives lost confirmed - death type'],\n",
    "              ['human lives lost - missing'],\n",
    "              ['human lives lost missing - type']\n",
    "              ]\n",
    "\n",
    "folder_slug_dict = dict()\n",
    "folder_slug_dict[0] ='RELIEF_DISTRIBUTED'\n",
    "folder_slug_dict[1] ='RELIEF_DISTRIBUTED_OTHERS'\n",
    "folder_slug_dict[2] ='RESCUE_OPERATION'\n",
    "folder_slug_dict[3] ='HOUSES_DAMAGED'\n",
    "folder_slug_dict[4] ='HUMAN_LIVES_LOST_CONFIRMED'\n",
    "folder_slug_dict[5] ='HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE'\n",
    "folder_slug_dict[6] ='HUMAN_LIVES_LOST_MISSING'\n",
    "folder_slug_dict[7] ='HUMAN_LIVES_LOST_MISSING_TYPE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca71cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "relief_distributed_issue_dates = []\n",
    "relief_distributed_others_issue_dates = []\n",
    "rescue_ops_issue_dates = []\n",
    "houses_damaged_issue_dates = []\n",
    "humanlives_confirmed_issues_dates = []\n",
    "humanlives_confirmed_deathtype_issues_dates = []\n",
    "humanlives_missing_issues_dates = []\n",
    "humanlives_missing_type_issues_dates = []\n",
    "\n",
    "issues_dates = [relief_distributed_issue_dates,\n",
    "                relief_distributed_others_issue_dates,\n",
    "                rescue_ops_issue_dates,\n",
    "                houses_damaged_issue_dates,\n",
    "                humanlives_confirmed_issues_dates,\n",
    "                humanlives_confirmed_deathtype_issues_dates,\n",
    "                humanlives_missing_issues_dates,\n",
    "                humanlives_missing_type_issues_dates\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e0491fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  01-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  01-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  01-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  01-08-2022\n",
      "----\n",
      "02.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "03.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "04.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "05.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "06.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  06.08.2022\n",
      "----\n",
      "07.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "08.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "09.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  09.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  09.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  09.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  09.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  09.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  09.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  09.08.2022\n",
      "----\n",
      "10.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "11.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "12.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "13.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "14.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "15.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "16.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "17.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "18.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "19.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "20.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "21.08.2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELIEF_DISTRIBUTED\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "22.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  22-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  22-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  22-08-2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  22-08-2022\n",
      "----\n",
      "23.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "24.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "25.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "26.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "27.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "28.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "29.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "30.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "31.08.2022\n",
      "RELIEF_DISTRIBUTED\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "RELIEF_DISTRIBUTED_OTHERS\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "RESCUE_OPERATION\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "HOUSES_DAMAGED\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_CONFIRMED_DEATHTYPE\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "HUMAN_LIVES_LOST_MISSING_TYPE\n",
      "No data for:  31.08.2022\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for date in dates:    \n",
    "    print(date)\n",
    "    FRIMS_pdf_file = r\"FRIMS_Reports/FRIMS_\"+date+\".pdf\"\n",
    "    tables = camelot.read_pdf(FRIMS_pdf_file,pages='all')\n",
    "    \n",
    "    FRIMS_DF = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0,len(tables)):\n",
    "        FRIMS_DF = pd.concat([FRIMS_DF,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.lower()\n",
    "    \n",
    "    for list_number, slug_list in enumerate(slug_lists):\n",
    "        folder_slug = folder_slug_dict[list_number]\n",
    "        print(folder_slug)\n",
    "        \n",
    "        try:\n",
    "            TABLE_START_INDEX = get_table_start_index(FRIMS_DF, slug_list)\n",
    "        except:\n",
    "            issues_dates[list_number].append(date)\n",
    "            print('Issue with table - Row header across multiple pages')\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        TABLE_END_INDEX = get_table_end_index(FRIMS_DF, TABLE_START_INDEX)\n",
    "\n",
    "        if TABLE_END_INDEX-1 <= TABLE_START_INDEX:\n",
    "            print(\"No data for: \",date)\n",
    "            #done_dates.append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        try:   \n",
    "            FRIMS_INFRA_DAMAGES_DF = extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX)\n",
    "        except:\n",
    "            print(\"Unable to extract for: \",date)\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        #FRIMS_INFRA_DAMAGES_DF['District'] = FRIMS_INFRA_DAMAGES_DF['District'].replace('',None).fillna(method='bfill')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF.drop_duplicates()\n",
    "        \n",
    "        \n",
    "        #done_dates.append(date)\n",
    "        date = date.replace('.','-')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.reset_index(drop=True).to_csv(r'Data/Scraped Data/'+folder_slug+r'/'+folder_slug+'_'+str(date)+'.csv')\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6befee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.DataFrame(issues_dates).T\n",
    "issues_df.columns = folder_slug_dict.values()\n",
    "issues_df.to_csv('ISSUES.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69cd2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_files_daily = glob.glob(r'Data/Scraped Data/HUMAN_LIVES_LOST_MISSING_TYPE/*.csv')\n",
    "\n",
    "dfs = []\n",
    "for file in scraped_files_daily:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.iloc[:-1,:]\n",
    "    dfs.append(df)\n",
    "    \n",
    "RELIEF_DISTRIBUTED = pd.concat(dfs)\n",
    "RELIEF_DISTRIBUTED['Date'] = pd.to_datetime(RELIEF_DISTRIBUTED['Date'],format='%d-%m-%Y')\n",
    "RELIEF_DISTRIBUTED = RELIEF_DISTRIBUTED.sort_values(by='Date')\n",
    "RELIEF_DISTRIBUTED.to_csv('Data/Cleaned Data/FRIMS_HUMAN_LIVES_LOST_MISSING_TYPE_MASTER_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934d888",
   "metadata": {},
   "source": [
    "# ANIMALS <a class=\"anchor\" id=\"animals\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac09e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for file in glob.glob(r'FRIMS_Reports/FRIMS_*.10*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "#done_dates = []\n",
    "issue_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5615c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_lists = [['animals affected','animal affected'],\n",
    "              ['animals washed away','animal washed away'],\n",
    "              ]\n",
    "\n",
    "folder_slug_dict = dict()\n",
    "folder_slug_dict[0] ='FRIMS_ANIMALS_AFFECTED'\n",
    "folder_slug_dict[1] ='FRIMS_ANIMALS_WASHED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7991316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_affected_issue_dates = []\n",
    "animals_washed_issue_dates = []\n",
    "\n",
    "issues_dates = [\n",
    "                animals_affected_issue_dates,\n",
    "    animals_washed_issue_dates,\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3895aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Total','Big','Small','Poultry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bb4d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  01.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  01.10.2022\n",
      "----\n",
      "02.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  02.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  02.10.2022\n",
      "----\n",
      "03.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "04.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "05.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "06.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "07.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  07.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  07.10.2022\n",
      "----\n",
      "08.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  08.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  08.10.2022\n",
      "----\n",
      "09.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  09-10-2022\n",
      "----\n",
      "10.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  10-10-2022\n",
      "----\n",
      "11.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  11-10-2022\n",
      "----\n",
      "12.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  12-10-2022\n",
      "----\n",
      "13.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  13-10-2022\n",
      "----\n",
      "14.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  14-10-2022\n",
      "----\n",
      "15.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  15-10-2022\n",
      "----\n",
      "16.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  16-10-2022\n",
      "----\n",
      "17.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  17-10-2022\n",
      "----\n",
      "18.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  18-10-2022\n",
      "----\n",
      "19.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  19.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  19.10.2022\n",
      "----\n",
      "20.10.2022\n",
      "FRIMS_ANIMALS_AFFECTED\n",
      "No data for:  20.10.2022\n",
      "----\n",
      "FRIMS_ANIMALS_WASHED\n",
      "No data for:  20.10.2022\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for date in dates:    \n",
    "    print(date)\n",
    "    FRIMS_pdf_file = r\"FRIMS_Reports/FRIMS_\"+date+\".pdf\"\n",
    "    tables = camelot.read_pdf(FRIMS_pdf_file,pages='all')\n",
    "    \n",
    "    FRIMS_DF = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0,len(tables)):\n",
    "        FRIMS_DF = pd.concat([FRIMS_DF,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.lower()\n",
    "    for list_number, slug_list in enumerate(slug_lists):\n",
    "        folder_slug = folder_slug_dict[list_number]\n",
    "        print(folder_slug)\n",
    "        \n",
    "        try:\n",
    "            TABLE_START_INDEX = get_table_start_index(FRIMS_DF, slug_list)\n",
    "        except:\n",
    "            issues_dates[list_number].append(date)\n",
    "            print('Issue with animals table - Row header across multiple pages')\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        TABLE_END_INDEX = get_table_end_index(FRIMS_DF, TABLE_START_INDEX)\n",
    "\n",
    "        if TABLE_END_INDEX-1 <= TABLE_START_INDEX:\n",
    "            print(\"No data for: \",date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:   \n",
    "            FRIMS_INFRA_DAMAGES_DF = extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX, column_names)\n",
    "        except:\n",
    "            print(\"Unable to extract for: \",date)\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        #FRIMS_INFRA_DAMAGES_DF['District'] = FRIMS_INFRA_DAMAGES_DF['District'].replace('',None).fillna(method='bfill')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF.drop_duplicates()\n",
    "        \n",
    "        \n",
    "        date = date.replace('.','-')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.reset_index(drop=True).to_csv(r'Data/Scraped Data/'+folder_slug+r'/'+folder_slug+'_'+str(date)+'.csv')\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "777ef048",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.DataFrame(issues_dates).T\n",
    "issues_df.columns = folder_slug_dict.values()\n",
    "issues_df.to_csv('ISSUES.csv',index=False)\n",
    "\n",
    "## PDFs on these dates are to be manually scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77539687",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_files_daily = glob.glob(r'Data/Scraped Data/FRIMS_ANIMALS_AFFECTED/*.csv')\n",
    "\n",
    "dfs = []\n",
    "for file in scraped_files_daily:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.iloc[:-1,:]\n",
    "    dfs.append(df)\n",
    "    \n",
    "FRIMS_ANIMALS_AFFECTED = pd.concat(dfs)\n",
    "FRIMS_ANIMALS_AFFECTED['Date'] = pd.to_datetime(FRIMS_ANIMALS_AFFECTED['Date'],format='%d-%m-%Y')\n",
    "FRIMS_ANIMALS_AFFECTED = FRIMS_ANIMALS_AFFECTED.sort_values(by='Date')\n",
    "FRIMS_ANIMALS_AFFECTED.to_csv('Data/Cleaned Data/FRIMS_ANIMALS_AFFECTED_MASTER_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee3503",
   "metadata": {},
   "source": [
    "# OTHER DAMAGES <a class=\"anchor\" id=\"otherdamages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a5549b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for file in glob.glob('FRIMS_Reports/FRIMS_*.08*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "issue_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ac33b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_lists = [['infrastructure damaged - others','infrastructure damaged - other'],\n",
    "              ['infrastructure damaged - wildlife'],\n",
    "              ['erosion'],\n",
    "              ['landslide','land slide','landslides','landslide'],\n",
    "              ['urban flood','urbanflood','urbanfloods','urban floods']\n",
    "              ]\n",
    "\n",
    "folder_slug_dict = dict()\n",
    "folder_slug_dict[0] ='FRIMS_OTHER_DAMAGES'\n",
    "folder_slug_dict[1] ='FRIMS_WILDLIFE'\n",
    "folder_slug_dict[2] ='FRIMS_EROSION'\n",
    "folder_slug_dict[3] ='FRIMS_LANDSLIDE'\n",
    "folder_slug_dict[4] ='FRIMS_URBANFLOOD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b711ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_damages_issue_dates = []\n",
    "wildlife_issue_dates = []\n",
    "erosion_issue_dates = []\n",
    "landslide_issue_dates = []\n",
    "urbanflood_issue_dates = []\n",
    "\n",
    "issues_dates = [other_damages_issue_dates,\n",
    "                wildlife_issue_dates,\n",
    "               erosion_issue_dates,\n",
    "                landslide_issue_dates,\n",
    "                urbanflood_issue_dates\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff503679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  01-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  01-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "02.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "03.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "04.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "05.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "06.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  06-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  06-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "07.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  07-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "08.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  08-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  08-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "09.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  09-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "10.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  10-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "11.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  11.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  11-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "12.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  12-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "13.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  13-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "14.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  14-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "15.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  15-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "16.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  16-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "17.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  17-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "18.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  18-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "19.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  19-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "20.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "21.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  21-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "22.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  22-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "23.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  23-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  23-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "24.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  24-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "25.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  25-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  25-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "26.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  26-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  26-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "27.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  27-08-2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  27-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "28.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  28-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "29.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  29-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "30.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  30-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n",
      "31.08.2022\n",
      "FRIMS_OTHER_DAMAGES\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "FRIMS_WILDLIFE\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "FRIMS_EROSION\n",
      "----\n",
      "FRIMS_LANDSLIDE\n",
      "No data for:  31-08-2022\n",
      "----\n",
      "FRIMS_URBANFLOOD\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for date in dates:    \n",
    "    print(date)\n",
    "    FRIMS_pdf_file = r\"FRIMS_Reports/FRIMS_\"+date+\".pdf\"\n",
    "    tables = camelot.read_pdf(FRIMS_pdf_file,pages='all')\n",
    "    \n",
    "    FRIMS_DF = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0,len(tables)):\n",
    "        FRIMS_DF = pd.concat([FRIMS_DF,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.lower()\n",
    "    for list_number, slug_list in enumerate(slug_lists):\n",
    "        folder_slug = folder_slug_dict[list_number]\n",
    "        print(folder_slug)\n",
    "        \n",
    "        if folder_slug=='FRIMS_OTHER_DAMAGES':\n",
    "            column_name = 'Other Details'\n",
    "        elif folder_slug == 'FRIMS_WILDLIFE':\n",
    "            column_name = 'Wildlife affected under protected areas description'\n",
    "        else:\n",
    "            column_name = 'Details'\n",
    "        \n",
    "        try:\n",
    "            TABLE_START_INDEX = get_table_start_index(FRIMS_DF, slug_list)\n",
    "        except:\n",
    "            issues_dates[list_number].append(date)\n",
    "            print('Issue with infra damages table - Row header across multiple pages')\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        if folder_slug=='FRIMS_URBANFLOOD':\n",
    "            TABLE_END_INDEX = TABLE_START_INDEX+100\n",
    "        else:\n",
    "            TABLE_END_INDEX = get_table_end_index(FRIMS_DF, TABLE_START_INDEX)\n",
    "\n",
    "            if TABLE_END_INDEX-1 <= TABLE_START_INDEX:\n",
    "                print(\"No data for: \",date)\n",
    "                print(\"----\")\n",
    "                continue\n",
    "        \n",
    "        try:   \n",
    "            FRIMS_INFRA_DAMAGES_DF = extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX, column_name)\n",
    "        except:\n",
    "            print(\"No dataa for: \",date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            FRIMS_INFRA_DAMAGES_DF['District'] = FRIMS_INFRA_DAMAGES_DF['District'].replace('',None).fillna(method='bfill')\n",
    "            g = FRIMS_INFRA_DAMAGES_DF.groupby('District')[column_name].transform(lambda x: ' '.join(x))\n",
    "        except:\n",
    "            print('Issues with cleaning and combining')\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        FRIMS_INFRA_DAMAGES_DF[column_name] = g\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF.drop_duplicates()\n",
    "        \n",
    "        date = date.replace('.','-')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.reset_index(drop=True).to_csv(r'Data/Scraped Data/'+folder_slug+r'/'+folder_slug+'_'+str(date)+'.csv')\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce809c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.DataFrame(issues_dates).T\n",
    "issues_df.columns = folder_slug_dict.values()\n",
    "issues_df.to_csv('ISSUES.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a194724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_files_daily = glob.glob(r'Data/Scraped Data/FRIMS_URBANFLOOD/*.csv')\n",
    "\n",
    "dfs = []\n",
    "for file in scraped_files_daily:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.iloc[:,:]\n",
    "    dfs.append(df)\n",
    "    \n",
    "FRIMS_EROSION = pd.concat(dfs)\n",
    "FRIMS_EROSION['Date'] = pd.to_datetime(FRIMS_EROSION['Date'],format='%d-%m-%Y')\n",
    "FRIMS_EROSION = FRIMS_EROSION.sort_values(by='Date')\n",
    "FRIMS_EROSION.to_csv('Data/Cleaned Data/FRIMS_URBANFLOOD_MASTER_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b754455",
   "metadata": {},
   "source": [
    "# INFRA DAMAGES <a class=\"anchor\" id=\"infradamages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a06a76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for file in glob.glob('FRIMS_Reports/FRIMS_*.08*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "for file in glob.glob('FRIMS_Reports/FRIMS_*.09*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "for file in glob.glob('FRIMS_Reports/FRIMS_*.10*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "issue_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38a7c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_lists = [['infrastructure damaged - road','infrastructure damaged - roads'],\n",
    "              ['infrastructure damaged - embankments affected','infrastructure damaged - embankment affected'],\n",
    "              ['infrastructure damaged - bridge','infrastructure damaged - bridges'],\n",
    "              ['infrastructure damaged - embankments breached','infrastructure damaged - embankment breached'],\n",
    "              ]\n",
    "\n",
    "folder_slug_dict = dict()\n",
    "folder_slug_dict[0] ='FRIMS_ROADS_DAMAGED'\n",
    "folder_slug_dict[1] ='FRIMS_EMBANKMENTS_AFFECTED'\n",
    "folder_slug_dict[2] ='FRIMS_BRIDGES_DAMAGED'\n",
    "folder_slug_dict[3] ='FRIMS_EMBANKMENTS_BREACHED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e397365",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_issue_dates = []\n",
    "embankment_affected_issue_dates = []\n",
    "bridge_issue_dates = []\n",
    "embankment_breached_issue_dates = []\n",
    "\n",
    "issues_dates = [road_issue_dates,\n",
    "                embankment_affected_issue_dates,\n",
    "               bridge_issue_dates,\n",
    "                embankment_breached_issue_dates,\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d4a94c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "02.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  02-08-2022\n",
      "----\n",
      "03.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  03-08-2022\n",
      "----\n",
      "04.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  04-08-2022\n",
      "----\n",
      "05.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  05-08-2022\n",
      "----\n",
      "06.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  06-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  06-08-2022\n",
      "----\n",
      "07.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "08.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  08-08-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  08-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  08-08-2022\n",
      "----\n",
      "09.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  09-08-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  09-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  09-08-2022\n",
      "----\n",
      "10.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  10.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  10.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  10.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  10.08.2022\n",
      "----\n",
      "11.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  11-08-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  11-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  11-08-2022\n",
      "----\n",
      "12.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "13.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "14.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "15.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "16.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "17.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "18.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "19.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "20.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "21.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  21-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  21-08-2022\n",
      "----\n",
      "22.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "23.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "24.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "25.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "26.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  26-08-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  26-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  26-08-2022\n",
      "----\n",
      "27.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "28.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "29.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "30.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "31.08.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  31-08-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  31-08-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  31-08-2022\n",
      "----\n",
      "01.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  01.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  01.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  01.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  01.09.2022\n",
      "----\n",
      "02.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  02-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  02-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  02-09-2022\n",
      "----\n",
      "03.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  03.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  03.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  03.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  03.09.2022\n",
      "----\n",
      "04.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  04.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  04.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  04.09.2022\n",
      "----\n",
      "05.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  05-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  05-09-2022\n",
      "----\n",
      "06.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  06-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  06-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "07.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  07-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  07-09-2022\n",
      "----\n",
      "08.09.2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  08-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  08-09-2022\n",
      "----\n",
      "09.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  09-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  09-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  09-09-2022\n",
      "----\n",
      "10.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  10-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  10-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  10-09-2022\n",
      "----\n",
      "11.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  11.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  11.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  11.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  11.09.2022\n",
      "----\n",
      "12.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  12-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  12-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  12-09-2022\n",
      "----\n",
      "13.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  13-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  13-09-2022\n",
      "----\n",
      "14.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  14-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  14-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "15.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  15-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  15-09-2022\n",
      "----\n",
      "16.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  16.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  16.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  16.09.2022\n",
      "----\n",
      "17.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  17.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  17.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  17.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  17.09.2022\n",
      "----\n",
      "18.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  18-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  18-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  18-09-2022\n",
      "----\n",
      "19.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  19.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  19.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  19.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  19.09.2022\n",
      "----\n",
      "20.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  20.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  20.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  20.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  20.09.2022\n",
      "----\n",
      "21.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  21.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  21-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  21-09-2022\n",
      "----\n",
      "22.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  22.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  22.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  22.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  22.09.2022\n",
      "----\n",
      "23.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  23.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  23.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  23.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  23.09.2022\n",
      "----\n",
      "24.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  24.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  24.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  24.09.2022\n",
      "----\n",
      "25.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  25.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  25-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  25-09-2022\n",
      "----\n",
      "26.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  26.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  26.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  26.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  26.09.2022\n",
      "----\n",
      "27.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  27-09-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  27-09-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  27-09-2022\n",
      "----\n",
      "28.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  28.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  28.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  28.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  28.09.2022\n",
      "----\n",
      "29.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  29.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  29.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  29.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  29.09.2022\n",
      "----\n",
      "30.09.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  30.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  30.09.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  30.09.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  30.09.2022\n",
      "----\n",
      "01.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  01.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  01.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  01-10-2022\n",
      "----\n",
      "02.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  02.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  02.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  02.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  02.10.2022\n",
      "----\n",
      "03.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "04.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "05.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "06.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "07.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  07.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  07.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  07.10.2022\n",
      "----\n",
      "08.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  08.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  08-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  08-10-2022\n",
      "----\n",
      "09.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  09.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  09.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  09.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  09.10.2022\n",
      "----\n",
      "10.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  10-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "----\n",
      "11.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  11-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  11-10-2022\n",
      "----\n",
      "12.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  12.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  12-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  12-10-2022\n",
      "----\n",
      "13.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  13-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  13-10-2022\n",
      "----\n",
      "14.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  14-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  14-10-2022\n",
      "----\n",
      "15.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  15-10-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  15-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  15-10-2022\n",
      "----\n",
      "16.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  16-10-2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  16-10-2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  16-10-2022\n",
      "----\n",
      "17.10.2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  17.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  17.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  17.10.2022\n",
      "----\n",
      "18.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  18.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  18.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  18.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  18.10.2022\n",
      "----\n",
      "19.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  19.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  19.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  19.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "Issue with infra damages table - Row header across multiple pages\n",
      "----\n",
      "20.10.2022\n",
      "FRIMS_ROADS_DAMAGED\n",
      "No data for:  20.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_AFFECTED\n",
      "No data for:  20.10.2022\n",
      "----\n",
      "FRIMS_BRIDGES_DAMAGED\n",
      "No data for:  20.10.2022\n",
      "----\n",
      "FRIMS_EMBANKMENTS_BREACHED\n",
      "No data for:  20.10.2022\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for date in dates:    \n",
    "    print(date)\n",
    "    FRIMS_pdf_file = r\"FRIMS_Reports/FRIMS_\"+date+\".pdf\"\n",
    "    tables = camelot.read_pdf(FRIMS_pdf_file,pages='all')\n",
    "    \n",
    "    FRIMS_DF = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0,len(tables)):\n",
    "        FRIMS_DF = pd.concat([FRIMS_DF,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.lower()\n",
    "    \n",
    "    for list_number, slug_list in enumerate(slug_lists):\n",
    "        folder_slug = folder_slug_dict[list_number]\n",
    "        print(folder_slug)\n",
    "        \n",
    "        if folder_slug=='FRIMS_OTHER_DAMAGES':\n",
    "            column_name = 'Other Details'\n",
    "        elif folder_slug == 'FRIMS_WILDLIFE':\n",
    "            column_name = 'Wildlife affected under protected areas description'\n",
    "        else:\n",
    "            column_name = 'Details'\n",
    "        \n",
    "        try:\n",
    "            TABLE_START_INDEX = get_table_start_index(FRIMS_DF, slug_list)\n",
    "        except:\n",
    "            issues_dates[list_number].append(date)\n",
    "            print('Issue with infra damages table - Row header across multiple pages')\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        if folder_slug=='FRIMS_URBANFLOOD':\n",
    "            TABLE_END_INDEX = TABLE_START_INDEX+100\n",
    "        else:\n",
    "            TABLE_END_INDEX = get_table_end_index(FRIMS_DF, TABLE_START_INDEX)\n",
    "\n",
    "            if TABLE_END_INDEX-1 <= TABLE_START_INDEX:\n",
    "                print(\"No data for: \",date)\n",
    "                #done_dates.append(date)\n",
    "                print(\"----\")\n",
    "                continue\n",
    "        \n",
    "        try:   \n",
    "            FRIMS_INFRA_DAMAGES_DF = extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX, column_name)\n",
    "        except:\n",
    "            print(\"No dataa for: \",date)\n",
    "            #issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            FRIMS_INFRA_DAMAGES_DF['District'] = FRIMS_INFRA_DAMAGES_DF['District'].replace('',None).fillna(method='bfill')\n",
    "            g = FRIMS_INFRA_DAMAGES_DF.groupby('District')[column_name].transform(lambda x: ' '.join(x))\n",
    "        except:\n",
    "            print('Issues with cleaning and combining')\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        FRIMS_INFRA_DAMAGES_DF[column_name] = g\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF.drop_duplicates()\n",
    "        \n",
    "        \n",
    "        date = date.replace('.','-')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.reset_index(drop=True).to_csv(r'Data/Scraped Data/'+folder_slug+r'/'+folder_slug+'_'+str(date)+'.csv')\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a36b6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.DataFrame(issues_dates).T\n",
    "issues_df.columns = folder_slug_dict.values()\n",
    "issues_df.to_csv('ISSUES.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c670a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_files_daily = glob.glob(r'Data/Scraped Data/FRIMS_EMBANKMENTS_BREACHED/*.csv')\n",
    "\n",
    "dfs = []\n",
    "for file in scraped_files_daily:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.iloc[:-1,:]\n",
    "    dfs.append(df)\n",
    "    \n",
    "FRIMS_BRIDGES_DAMAGED = pd.concat(dfs)\n",
    "FRIMS_BRIDGES_DAMAGED['Date'] = pd.to_datetime(FRIMS_BRIDGES_DAMAGED['Date'],format='%d-%m-%Y')\n",
    "FRIMS_BRIDGES_DAMAGED = FRIMS_BRIDGES_DAMAGED.sort_values(by='Date')\n",
    "FRIMS_BRIDGES_DAMAGED=FRIMS_BRIDGES_DAMAGED[['District','Number','Details','Date']]\n",
    "FRIMS_BRIDGES_DAMAGED.drop_duplicates().dropna().to_csv('Data/Cleaned Data/FRIMS_DAMAGE_EMBANKMENT_BREACHED_MASTER_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda3ab1",
   "metadata": {},
   "source": [
    "# Population affected, Crop Area Affected, Relief camps <a class=\"anchor\" id=\"population\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "52eeef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for file in glob.glob('FRIMS_Reports/FRIMS_*.pdf'):\n",
    "    date = file.split('FRIMS_')[-1].split('.pdf')[0]\n",
    "    dates.append(date)\n",
    "\n",
    "done_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ad2a32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_lists = [['population and crop area affected'],\n",
    "              ['relief camps /centres opened','relief camps / centres opened'],\n",
    "              ['inmates in relief camps'],\n",
    "              ]\n",
    "\n",
    "folder_slug_dict = dict()\n",
    "folder_slug_dict[0] ='POPULATION_AND_CROP_AREA_AFFECTED'\n",
    "folder_slug_dict[1] ='RELIEF_CAMPS_OPENED'\n",
    "folder_slug_dict[2] ='RELIEF_CAMP_INMATES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7e3a33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_issue_dates = []\n",
    "camps_issue_dates = []\n",
    "inmates_issue_dates = []\n",
    "\n",
    "issues_dates = [pop_issue_dates,\n",
    "                camps_issue_dates,\n",
    "               inmates_issue_dates,\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8d2d56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  07.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  07.09.2022\n",
      "----\n",
      "06.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "27.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  27.08.2022\n",
      "----\n",
      "15.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "17.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  17.08.2022\n",
      "----\n",
      "18.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "11.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  11.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  11.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  11.09.2022\n",
      "----\n",
      "16.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  16.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  16.10.2022\n",
      "----\n",
      "05.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "22.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "09.08.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "29.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  29.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  29.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  29.09.2022\n",
      "----\n",
      "20.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  20.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  20.10.2022\n",
      "----\n",
      "06.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  06.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  06.09.2022\n",
      "----\n",
      "09.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  09.06.2022\n",
      "----\n",
      "11.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  11.10.2022\n",
      "----\n",
      "30.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  30.08.2022\n",
      "----\n",
      "14.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  14.09.2022\n",
      "----\n",
      "23.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "09.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  09.09.2022\n",
      "----\n",
      "19.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  19.08.2022\n",
      "----\n",
      "11.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "28.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  28.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  28.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  28.09.2022\n",
      "----\n",
      "18.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  18.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  18.10.2022\n",
      "----\n",
      "25.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  25.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  25.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  25.09.2022\n",
      "----\n",
      "04.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  04.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  04.09.2022\n",
      "----\n",
      "17.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  17.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  17.10.2022\n",
      "----\n",
      "26.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "10.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  10.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  10.09.2022\n",
      "----\n",
      "24.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "17.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "29.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "23.05.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "04.10.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  04.10.2022\n",
      "----\n",
      "22.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  22.08.2022\n",
      "----\n",
      "31.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "24.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  24.08.2022\n",
      "----\n",
      "31.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  31.08.2022\n",
      "----\n",
      "23.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  23.08.2022\n",
      "----\n",
      "21.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "24.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "19.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "12.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "05.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  05.10.2022\n",
      "----\n",
      "03.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  03.10.2022\n",
      "----\n",
      "25.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "27.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  27.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  27.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  27.09.2022\n",
      "----\n",
      "29.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "30.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "21.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "07.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "07.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "12.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  12.08.2022\n",
      "----\n",
      "21.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  21.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  21.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  21.09.2022\n",
      "----\n",
      "09.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "26.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "06.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "06.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "12.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  12.10.2022\n",
      "----\n",
      "23.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  23.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  23.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  23.09.2022\n",
      "----\n",
      "26.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  26.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  26.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  26.09.2022\n",
      "----\n",
      "11.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  11.06.2022\n",
      "----\n",
      "23.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "30.09.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  30.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  30.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  30.09.2022\n",
      "----\n",
      "15.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "19.05.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "06.10.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  06.10.2022\n",
      "----\n",
      "27.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "18.09.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  18.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  18.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  18.09.2022\n",
      "----\n",
      "28.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  28.08.2022\n",
      "----\n",
      "08.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  08.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  08.10.2022\n",
      "----\n",
      "15.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  15.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  15.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  15.09.2022\n",
      "----\n",
      "13.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  13.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  13.09.2022\n",
      "----\n",
      "28.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "08.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  08.09.2022\n",
      "----\n",
      "10.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "17.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "17.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  17.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  17.09.2022\n",
      "----\n",
      "19.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "27.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "09.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  09.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  09.10.2022\n",
      "----\n",
      "05.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  05.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  05.09.2022\n",
      "----\n",
      "25.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  25.08.2022\n",
      "----\n",
      "07.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  07.08.2022\n",
      "----\n",
      "21.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "16.09.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  16.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  16.09.2022\n",
      "----\n",
      "20.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  20.08.2022\n",
      "----\n",
      "15.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  15.08.2022\n",
      "----\n",
      "26.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "13.08.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  13.08.2022\n",
      "----\n",
      "14.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "14.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "19.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  19.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  19.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  19.09.2022\n",
      "----\n",
      "10.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  10.06.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  10.06.2022\n",
      "----\n",
      "16.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  16.08.2022\n",
      "----\n",
      "04.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "10.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  10.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  10.10.2022\n",
      "----\n",
      "08.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "20.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  20.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  20.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  20.09.2022\n",
      "----\n",
      "25.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "18.05.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "20.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "04.08.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "30.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issue with table - Row header across multiple pages\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "21.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  21.08.2022\n",
      "----\n",
      "18.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  18.08.2022\n",
      "----\n",
      "28.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "05.07.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "22.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  22.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  22.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  22.09.2022\n",
      "----\n",
      "26.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  26.08.2022\n",
      "----\n",
      "27.05.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "29.08.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  29.08.2022\n",
      "----\n",
      "12.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  12.06.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  12.06.2022\n",
      "----\n",
      "30.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "20.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "07.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  07.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  07.10.2022\n",
      "----\n",
      "13.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  13.06.2022\n",
      "----\n",
      "15.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "11.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "14.10.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  14.10.2022\n",
      "----\n",
      "24.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "22.07.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "24.09.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  24.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  24.09.2022\n",
      "----\n",
      "28.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "05.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "10.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "15.10.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  15.10.2022\n",
      "----\n",
      "18.06.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "12.09.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "No data for:  12.09.2022\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  12.09.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  12.09.2022\n",
      "----\n",
      "17.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "13.10.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  13.10.2022\n",
      "----\n",
      "25.05.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "14.08.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  14.08.2022\n",
      "----\n",
      "20.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "08.08.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  08.08.2022\n",
      "----\n",
      "13.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "Issues with cleaning and combining\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "08.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "16.05.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "16.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "29.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "19.10.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "No data for:  19.10.2022\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "No data for:  19.10.2022\n",
      "----\n",
      "04.07.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "22.05.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikr\\AppData\\Local\\Temp/ipykernel_18920/520012954.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n",
      "16.06.2022\n",
      "POPULATION_AND_CROP_AREA_AFFECTED\n",
      "----\n",
      "RELIEF_CAMPS_OPENED\n",
      "----\n",
      "RELIEF_CAMP_INMATES\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for date in list(set(dates)-set(done_dates)):\n",
    "    done_dates.append(date)\n",
    "    print(date)\n",
    "    FRIMS_pdf_file = r\"FRIMS_Reports/FRIMS_\"+date+\".pdf\"\n",
    "    tables = camelot.read_pdf(FRIMS_pdf_file,pages='all')\n",
    "    \n",
    "    FRIMS_DF = pd.DataFrame()\n",
    "    for i in range(0,len(tables)):\n",
    "        FRIMS_DF = pd.concat([FRIMS_DF,tables[i].df],axis=0, ignore_index=True)\n",
    "    \n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.replace(r'\\n','',regex=True)\n",
    "    FRIMS_DF[0] = FRIMS_DF[0].str.lower()\n",
    "    \n",
    "    \n",
    "    for list_number, slug_list in enumerate(slug_lists):\n",
    "        folder_slug = folder_slug_dict[list_number]\n",
    "        print(folder_slug)\n",
    "        \n",
    "        if folder_slug=='POPULATION_AND_CROP_AREA_AFFECTED':\n",
    "            column_name = ['Population Details','Crop Area Details']\n",
    "        elif folder_slug == 'RELIEF_CAMPS_OPENED':\n",
    "            column_name = ['Relief Camp','Relief Distribution Centres']\n",
    "        elif folder_slug == 'RELIEF_CAMP_INMATES':\n",
    "            column_name = ['Revenue Circlewise']\n",
    "        \n",
    "        try:\n",
    "            TABLE_START_INDEX = get_table_start_index(FRIMS_DF, slug_list)\n",
    "        except:\n",
    "            issues_dates[list_number].append(date)\n",
    "            print('Issue with table - Row header across multiple pages')\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        TABLE_END_INDEX = get_table_end_index(FRIMS_DF, TABLE_START_INDEX)\n",
    "\n",
    "        if TABLE_END_INDEX-1 <= TABLE_START_INDEX:\n",
    "            print(\"No data for: \",date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        try:   \n",
    "            FRIMS_INFRA_DAMAGES_DF = extract_infra_damages_data(FRIMS_DF, TABLE_START_INDEX, TABLE_END_INDEX, column_names).reset_index(drop=True)\n",
    "        except:\n",
    "            print(\"Unable to extract for: \",date)\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "        \n",
    "        FRIMS_INFRA_DAMAGES_DF['District'] = FRIMS_INFRA_DAMAGES_DF['District'].replace('',None).fillna(method='bfill')\n",
    "        \n",
    "        try:\n",
    "            FRIMS_INFRA_DAMAGES_DF[column_name]\n",
    "        except:\n",
    "            print('Issues with cleaning and combining')\n",
    "            issues_dates[list_number].append(date)\n",
    "            print(\"----\")\n",
    "            continue\n",
    "            \n",
    "        for idx, row in FRIMS_INFRA_DAMAGES_DF.loc[:-1,:].iterrows():\n",
    "            for column in column_name:\n",
    "                if len(row[column])<10:\n",
    "                    FRIMS_INFRA_DAMAGES_DF.loc[idx,column] = FRIMS_INFRA_DAMAGES_DF.iloc[idx,1+list(FRIMS_INFRA_DAMAGES_DF.columns).index(column)]\n",
    "            \n",
    "                \n",
    "        for column in column_name:\n",
    "            FRIMS_INFRA_DAMAGES_DF[column] = FRIMS_INFRA_DAMAGES_DF[column].astype(str)\n",
    "            g = FRIMS_INFRA_DAMAGES_DF.groupby('District')[column].transform(lambda x: ' '.join(x))\n",
    "            FRIMS_INFRA_DAMAGES_DF[column] = g\n",
    "            \n",
    "        \n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED = FRIMS_INFRA_DAMAGES_DF.drop_duplicates(subset='District',keep='first')\n",
    "        \n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED['Date'] = date.replace('.','-')\n",
    "        FRIMS_INFRA_DAMAGES_DF_CLEANED.reset_index(drop=True).to_csv(r'Data/Scraped Data/'+folder_slug+r'/'+folder_slug+'_'+str(date.replace('.','-'))+'.csv')\n",
    "        \n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a8d32008",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.DataFrame(issues_dates).T\n",
    "issues_df.columns = folder_slug_dict.values()\n",
    "issues_df.to_csv('ISSUES.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d971e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_files_daily = glob.glob(r'Data/Scraped Data/RELIEF_CAMP_INMATES/*.csv')\n",
    "\n",
    "dfs = []\n",
    "for file in scraped_files_daily:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.iloc[:-1,:]\n",
    "    dfs.append(df)\n",
    "    \n",
    "DF = pd.concat(dfs)\n",
    "DF['Date'] = pd.to_datetime(DF['Date'],format='%d-%m-%Y')\n",
    "DF = DF.sort_values(by='Date')\n",
    "DF.drop_duplicates().to_csv('Data/Cleaned Data/RELIEF_CAMP_INMATES_MASTER_2022.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
